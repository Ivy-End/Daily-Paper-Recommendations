## 每日论文推荐 — 2025-10-23

- **KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models**
  - 发表日期：2025-10-23 | 推荐度：0.852 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20278v1
  - 摘要：In recent years, Pretrained Large Models(PLMs) researchers proposed
large-small model collaboration frameworks, leveraged easily trainable small
models to assist large models, aim to(1) significantly reduce computational
resource consumption while maintaining comparable accuracy, and (2) enhance
large model performance in specialized domain tasks. However, this
collaborative paradigm suffers from issues such as significant accuracy
degradation, exacerbated catastrophic forgetting, and amplified hallucination
problems induced by small model knowledge. To address these challenges, we
propose a KAN-based Collaborative Model (KCM) as an improved approach to
large-small model collaboration. The KAN utilized in KCM represents an
alternative neural network architecture distinct from conventional MLPs.
Compared to MLPs, KAN offers superior visualizability and interpretability
while mitigating catastrophic forgetting. We deployed KCM in large-small model
collaborative systems across three scenarios: language, vision, and
vision-language cross-modal tasks. The experimental results demonstrate that,
compared with pure large model approaches, the large-small model collaboration
framework utilizing KCM as the collaborative model significantly reduces the
number of large model inference calls while maintaining near-identical task
accuracy, thereby substantially lowering computational resource consumption.
Concurrently, the KAN-based small collaborative model markedly mitigates
catastrophic forgetting, leading to significant accuracy improvements for
long-tail data. The results reveal that KCM demonstrates superior performance
across all metrics compared to MLP-based small collaborative models (MCM).

- **A Multifunctional Capacitive Sensing Platform for Wireless Vascular and
  Heart Monitoring**
  - 发表日期：2025-10-23 | 推荐度：0.848 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20415v1
  - 摘要：We present a multifunctional, antenna-integrated capacitive sensing (MAiCaS)
platform for passive, wireless, and real-time cardiovascular monitoring. Unlike
conventional systems that require separate sensors and wireless modules, our
device unifies sensing, telemetry, and mechanical functionality into a compact
and scalable design by exploiting the parasitic capacitance of an inductive
antenna as a strain-sensitive element. The sensor is fabricated using a
cleanroom-free, single-step UV laser patterning process on a flexible PDMS
substrate, reducing manufacturing complexity and enabling high reproducibility.
The MAiCaS is suitable for three different applications: as a sensor for
epicardial strain measurement, a stent as a sensor, and a vascular graft
sensor. We demonstrate MAiCaS's versatility by validating its wireless
resonance-based response to strain, pressure, and deformation across unrolled
and rolled forms. In vitro experiments demonstrated consistent resonance
frequency shifts under physiological conditions, with stable performance on
skin, in PBS, human serum, and simulated vascular environments. Repeatability
and aging tests confirmed its long-term reliability and elasticity under cyclic
loading. Calibration curves revealed high sensitivity across all
configurations, with wireless interrogation achieved through S11 parameter
measurements and resonance frequency shift as the output metric. The
sensitivity of the device was measured to be 2.9 MHz per 1% strain, 0.43
MHz/mmHg, and 309.6kHz/\textmu m for epicardial patch, graft, and stent
integrated sensor, respectively. The operation of MAiCaS was evaluated in a
human experiment. This monolithic sensor architecture provides a scalable and
cost-effective solution for battery-free monitoring of vascular dynamics, with
potential for remote diagnostics, post-surgical follow-up, and continuous
cardiovascular health management.

- **SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal
  Alignment**
  - 发表日期：2025-10-23 | 推荐度：0.845 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20540v1
  - 摘要：Conventional multimodal alignment methods assume mutual redundancy across all
modalities, an assumption that fails in real-world distributed scenarios. We
propose SheafAlign, a sheaf-theoretic framework for decentralized multimodal
alignment that replaces single-space alignment with multiple comparison spaces.
This approach models pairwise modality relations through sheaf structures and
leverages decentralized contrastive learning-based objectives for training.
SheafAlign overcomes the limitations of prior methods by not requiring mutual
redundancy among all modalities, preserving both shared and unique information.
Experiments on multimodal sensing datasets show superior zero-shot
generalization, cross-modal alignment, and robustness to missing modalities,
with 50\% lower communication cost than state-of-the-art baselines.

- **Synthetic Data for Robust Runway Detection**
  - 发表日期：2025-10-23 | 推荐度：0.844 | 来源：arXiv
  - DOI：10.1007/978-3-032-04968-1_25
  - 链接：http://arxiv.org/abs/2510.20349v1
  - 摘要：Deep vision models are now mature enough to be integrated in industrial and
possibly critical applications such as autonomous navigation. Yet, data
collection and labeling to train such models requires too much efforts and
costs for a single company or product. This drawback is more significant in
critical applications, where training data must include all possible conditions
including rare scenarios. In this perspective, generating synthetic images is
an appealing solution, since it allows a cheap yet reliable covering of all the
conditions and environments, if the impact of the synthetic-to-real
distribution shift is mitigated. In this article, we consider the case of
runway detection that is a critical part in autonomous landing systems
developed by aircraft manufacturers. We propose an image generation approach
based on a commercial flight simulator that complements a few annotated real
images. By controlling the image generation and the integration of real and
synthetic data, we show that standard object detection models can achieve
accurate prediction. We also evaluate their robustness with respect to adverse
conditions, in our case nighttime images, that were not represented in the real
data, and show the interest of using a customized domain adaptation strategy.

- **In-DRAM True Random Number Generation Using Simultaneous Multiple-Row
  Activation: An Experimental Study of Real DRAM Chips**
  - 发表日期：2025-10-23 | 推荐度：0.844 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20269v1
  - 摘要：In this work, we experimentally demonstrate that it is possible to generate
true random numbers at high throughput and low latency in commercial
off-the-shelf (COTS) DRAM chips by leveraging simultaneous multiple-row
activation (SiMRA) via an extensive characterization of 96 DDR4 DRAM chips. We
rigorously analyze SiMRA's true random generation potential in terms of
entropy, latency, and throughput for varying numbers of simultaneously
activated DRAM rows (i.e., 2, 4, 8, 16, and 32), data patterns, temperature
levels, and spatial variations. Among our 11 key experimental observations, we
highlight four key results. First, we evaluate the quality of our TRNG designs
using the commonly-used NIST statistical test suite for randomness and find
that all SiMRA-based TRNG designs successfully pass each test. Second, 2-, 8-,
16-, and 32-row activation-based TRNG designs outperform the state-of-theart
DRAM-based TRNG in throughput by up to 1.15x, 1.99x, 1.82x, and 1.39x,
respectively. Third, SiMRA's entropy tends to increase with the number of
simultaneously activated DRAM rows. Fourth, operational parameters and
conditions (e.g., data pattern and temperature) significantly affect entropy.
For example, for most of the tested modules, the average entropy of 32-row
activation is 2.51x higher than that of 2-row activation. For example,
increasing the temperature from 50{\deg}C to 90{\deg}C decreases SiMRA's
entropy by 1.53x for 32-row activation. To aid future research and development,
we open-source our infrastructure at https://github.com/CMU-SAFARI/SiMRA-TRNG.

- **Downsizing Diffusion Models for Cardinality Estimation**
  - 发表日期：2025-10-23 | 推荐度：0.841 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20681v1
  - 摘要：Inspired by the performance of score-based diffusion models in estimating
complex text, video, and image distributions with thousands of dimensions, we
introduce Accelerated Diffusion Cardest (ADC), the first joint distribution
cardinality estimator based on a downsized diffusion model.
  To calculate the pointwise density value of data distributions, ADC's density
estimator uses a formula that evaluates log-likelihood by integrating the score
function, a gradient mapping which ADC has learned to efficiently approximate
using its lightweight score estimator. To answer ranged queries, ADC's
selectivity estimator first predicts their selectivity using a Gaussian Mixture
Model (GMM), then uses importance sampling Monte Carlo to correct its
predictions with more accurate pointwise density values calculated by the
density estimator. ADC+ further trains a decision tree to identify the
high-volume, high-selectivity queries that the GMM alone can predict very
accurately, in which case it skips the correction phase to prevent Monte Carlo
from adding more variance. Doing so lowers median Q-error and cuts per-query
latency by 25 percent, making ADC+ usually twice as fast as Naru, arguably the
state-of-the-art joint distribution cardinality estimator.
  Numerical experiments using well-established benchmarks show that on all
real-world datasets tested, ADC+ is capable of rivaling Naru and outperforming
MSCN, DeepDB, LW-Tree, and LW-NN using around 66 percent their storage space,
being at least 3 times as accurate as MSCN on 95th and 99th percentile error.
Furthermore, on a synthetic dataset where attributes exhibit complex,
multilateral correlations, ADC and ADC+ are considerably robust while almost
every other learned model suffered significant accuracy declines. In this case,
ADC+ performs better than any other tested model, being 10 times as accurate as
Naru on 95th and 99th percentile error.

- **Mixing Importance with Diversity: Joint Optimization for KV Cache
  Compression in Large Vision-Language Models**
  - 发表日期：2025-10-23 | 推荐度：0.839 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20707v1
  - 摘要：Recent large vision-language models (LVLMs) demonstrate remarkable
capabilities in processing extended multi-modal sequences, yet the resulting
key-value (KV) cache expansion creates a critical memory bottleneck that
fundamentally limits deployment scalability. While existing KV cache
compression methods focus on retaining high-importance KV pairs to minimize
storage, they often overlook the modality-specific semantic redundancy patterns
that emerge distinctively in multi-modal KV caches. In this work, we first
analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying
levels of redundancy across attention heads. We show that relying solely on
importance can only cover a subset of the full KV cache information
distribution, leading to potential loss of semantic coverage. To address this,
we propose \texttt{MixKV}, a novel method that mixes importance with diversity
for optimized KV cache compression in LVLMs. \texttt{MixKV} adapts to head-wise
semantic redundancy, selectively balancing diversity and importance when
compressing KV pairs. Extensive experiments demonstrate that \texttt{MixKV}
consistently enhances existing methods across multiple LVLMs. Under extreme
compression (budget=64), \texttt{MixKV} improves baseline methods by an average
of \textbf{5.1\%} across five multi-modal understanding benchmarks and achieves
remarkable gains of \textbf{8.0\%} and \textbf{9.0\%} for SnapKV and AdaKV on
GUI grounding tasks, all while maintaining comparable inference efficiency.
Furthermore, \texttt{MixKV} extends seamlessly to LLMs with comparable
performance gains. Our code is available at
\href{https://github.com/xuyang-liu16/MixKV}{\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.

- **Multi-layer Optimized Coordination of Smart Building Resources in Active
  Power Distribution Systems**
  - 发表日期：2025-10-23 | 推荐度：0.837 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20313v1
  - 摘要：This paper proposes a multi-actor coordination platform for the optimal
utilization of smart buildings resources, including roof top PV generation and
battery energy storage system (BESS), in active power distribution systems. The
proposed multi-actor coordination includes the Smart Building Coordinator
(SBC), Micro-Grid Coordinator (MGC) and Distribution System Coordinator (DSC).
The coordinators operate independently and only exchange limited information
with each other to reach an optimal solution. In the proposed platform, a
hierarchical optimization problem is solved to optimally determine the
operating point of all distribution system resources. The proposed platform
fully preserves the confidentiality of the behind the meter (BTM) data of the
buildings since no information about the status of the PV system, BESS, and
load of the building is shared with the owner of the power system. The proposed
platform has a flexible and scalable architecture where the computational task
of coordinating microgrids and smart buildings with distribution grid is
performed locally at the MGC and SBC layers, respectively. Numerical
simulations show the efficacy of the proposed platform in coordinating the BTM
resources with the rest of the distribution system.

- **ComProScanner: A multi-agent based framework for composition-property
  structured data extraction from scientific literature**
  - 发表日期：2025-10-23 | 推荐度：0.833 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20362v1
  - 摘要：Since the advent of various pre-trained large language models, extracting
structured knowledge from scientific text has experienced a revolutionary
change compared with traditional machine learning or natural language
processing techniques. Despite these advances, accessible automated tools that
allow users to construct, validate, and visualise datasets from scientific
literature extraction remain scarce. We therefore developed ComProScanner, an
autonomous multi-agent platform that facilitates the extraction, validation,
classification, and visualisation of machine-readable chemical compositions and
properties, integrated with synthesis data from journal articles for
comprehensive database creation. We evaluated our framework using 100 journal
articles against 10 different LLMs, including both open-source and proprietary
models, to extract highly complex compositions associated with ceramic
piezoelectric materials and corresponding piezoelectric strain coefficients
(d33), motivated by the lack of a large dataset for such materials.
DeepSeek-V3-0324 outperformed all models with a significant overall accuracy of
0.82. This framework provides a simple, user-friendly, readily-usable package
for extracting highly complex experimental data buried in the literature to
build machine learning or deep learning datasets.

- **A computational model and tool for generating more novel opportunities
  in professional innovation processes**
  - 发表日期：2025-10-23 | 推荐度：0.833 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20402v1
  - 摘要：This paper presents a new computational model of creative outcomes, informed
by creativity theories and techniques, which was implemented to generate more
novel opportunities for innovation projects. The model implemented five
functions that were developed to contribute to the generation of innovation
opportunities with higher novelty without loss of usefulness. The model was
evaluated using opportunities generated for an innovation project in the
hospitality sector. The evaluation revealed that the computational model
generated outcomes that were more novel and/or useful than outcomes from
Notebook LM and ChatGPT4o. However, not all model functions contributed to the
generation of more novel opportunities, leading to new directions for further
model development

- **Deep Learning in Dental Image Analysis: A Systematic Review of Datasets,
  Methodologies, and Emerging Challenges**
  - 发表日期：2025-10-23 | 推荐度：0.833 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20634v1
  - 摘要：Efficient analysis and processing of dental images are crucial for dentists
to achieve accurate diagnosis and optimal treatment planning. However, dental
imaging inherently poses several challenges, such as low contrast, metallic
artifacts, and variations in projection angles. Combined with the subjectivity
arising from differences in clinicians' expertise, manual interpretation often
proves time-consuming and prone to inconsistency. Artificial intelligence
(AI)-based automated dental image analysis (DIA) offers a promising solution to
these issues and has become an integral part of computer-aided dental diagnosis
and treatment. Among various AI technologies, deep learning (DL) stands out as
the most widely applied and influential approach due to its superior feature
extraction and representation capabilities. To comprehensively summarize recent
progress in this field, we focus on the two fundamental aspects of DL
research-datasets and models. In this paper, we systematically review 260
studies on DL applications in DIA, including 49 papers on publicly available
dental datasets and 211 papers on DL-based algorithms. We first introduce the
basic concepts of dental imaging and summarize the characteristics and
acquisition methods of existing datasets. Then, we present the foundational
techniques of DL and categorize relevant models and algorithms according to
different DIA tasks, analyzing their network architectures, optimization
strategies, training methods, and performance. Furthermore, we summarize
commonly used training and evaluation metrics in the DIA domain. Finally, we
discuss the current challenges of existing research and outline potential
future directions. We hope that this work provides a valuable and systematic
reference for researchers in this field. All supplementary materials and
detailed comparison tables will be made publicly available on GitHub.

- **ALICE-LRI: A General Method for Lossless Range Image Generation for
  Spinning LiDAR Sensors without Calibration Metadata**
  - 发表日期：2025-10-23 | 推荐度：0.833 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20708v1
  - 摘要：3D LiDAR sensors are essential for autonomous navigation, environmental
monitoring, and precision mapping in remote sensing applications. To
efficiently process the massive point clouds generated by these sensors, LiDAR
data is often projected into 2D range images that organize points by their
angular positions and distances. While these range image representations enable
efficient processing, conventional projection methods suffer from fundamental
geometric inconsistencies that cause irreversible information loss,
compromising high-fidelity applications. We present ALICE-LRI (Automatic LiDAR
Intrinsic Calibration Estimation for Lossless Range Images), the first general,
sensor-agnostic method that achieves lossless range image generation from
spinning LiDAR point clouds without requiring manufacturer metadata or
calibration files. Our algorithm automatically reverse-engineers the intrinsic
geometry of any spinning LiDAR sensor by inferring critical parameters
including laser beam configuration, angular distributions, and per-beam
calibration corrections, enabling lossless projection and complete point cloud
reconstruction with zero point loss. Comprehensive evaluation across the
complete KITTI and DurLAR datasets demonstrates that ALICE-LRI achieves perfect
point preservation, with zero points lost across all point clouds. Geometric
accuracy is maintained well within sensor precision limits, establishing
geometric losslessness with real-time performance. We also present a
compression case study that validates substantial downstream benefits,
demonstrating significant quality improvements in practical applications. This
paradigm shift from approximate to lossless LiDAR projections opens new
possibilities for high-precision remote sensing applications requiring complete
geometric preservation.

- **Performance of an open-source image-based history matching framework for
  CO$_2$ storage**
  - 发表日期：2025-10-23 | 推荐度：0.832 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20614v1
  - 摘要：We present a history matching (HM) workflow applied to the International
FluidFlower benchmark study dataset, which features high-resolution images of
CO$_2$ storage in a meter-scale, geologically complex reservoir. The dataset
provides dense spatial and temporal observations of fluid displacement,
offering a rare opportunity to validate and enhance HM techniques for
geological carbon storage (GCS). The combination of detailed experimental data
and direct visual observation of flow behavior at this scale is novel and
valuable. This study explores the potential and limitations of using
experimental data to calibrate standard models for GCS simulation. By
leveraging high-resolution images and resulting interpretations of fluid phase
distributions, we adjust uncertain parameters and reduce the mismatch between
simulation results and observed data. Simulations are performed using the
open-source OPM Flow simulator, while the open-source Everest decision-making
tool is employed to conduct the HM. After the HM process, the final simulation
results show good agreement with the experimental CO$_2$ storage data. This
suggests that the system can be effectively described using standard flow
equations, conventional saturation functions, and typical PVT properties for
CO$_2$-brine mixtures. Our results demonstrate that the Wasserstein distance is
a particularly effective metric for matching multi-phase, multi-component flow
data. The entire workflow is implemented in a Python package named pofff
(Python OPM Flow FluidFlower), which organizes all functionality through a
single input file. This design ensures reproducibility and facilitates future
extensions of the study.

- **Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization
  Leveraging LiDAR-Based Robot Detections**
  - 发表日期：2025-10-23 | 推荐度：0.831 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20480v1
  - 摘要：Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

- **Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous
  Parking**
  - 发表日期：2025-10-23 | 推荐度：0.831 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20335v1
  - 摘要：Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

- **Learning Optimal Power Flow with Pointwise Constraints**
  - 发表日期：2025-10-23 | 推荐度：0.830 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20777v1
  - 摘要：Training learning parameterizations to solve optimal power flow (OPF) with
pointwise constraints is proposed. In this novel training approach, a learning
parameterization is substituted directly into an OPF problem with constraints
required to hold over all problem instances. This is different from existing
supervised learning methods in which constraints are required to hold across
the average of problem instances. Training with pointwise constraints is
undertaken in the dual domain with the use of augmented Lagrangian and dual
gradient ascent algorithm. Numerical experiments demonstrate that training with
pointwise constraints produces solutions with smaller constraint violations.
Experiments further demonstrated that pointwise constraints are most effective
at reducing constraint violations in corner cases - defined as those
realizations in which constraints are most difficult to satisfy. Gains are most
pronounced in power systems with large numbers of buses.

- **Empower Words: DualGround for Structured Phrase and Sentence-Level
  Temporal Grounding**
  - 发表日期：2025-10-23 | 推荐度：0.830 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20244v1
  - 摘要：Video Temporal Grounding (VTG) aims to localize temporal segments in long,
untrimmed videos that align with a given natural language query. This task
typically comprises two subtasks: Moment Retrieval (MR) and Highlight Detection
(HD). While recent advances have been progressed by powerful pretrained
vision-language models such as CLIP and InternVideo2, existing approaches
commonly treat all text tokens uniformly during crossmodal attention,
disregarding their distinct semantic roles. To validate the limitations of this
approach, we conduct controlled experiments demonstrating that VTG models
overly rely on [EOS]-driven global semantics while failing to effectively
utilize word-level signals, which limits their ability to achieve fine-grained
temporal alignment. Motivated by this limitation, we propose DualGround, a
dual-branch architecture that explicitly separates global and local semantics
by routing the [EOS] token through a sentence-level path and clustering word
tokens into phrase-level units for localized grounding. Our method introduces
(1) tokenrole- aware cross modal interaction strategies that align video
features with sentence-level and phrase-level semantics in a structurally
disentangled manner, and (2) a joint modeling framework that not only improves
global sentence-level alignment but also enhances finegrained temporal
grounding by leveraging structured phrase-aware context. This design allows the
model to capture both coarse and localized semantics, enabling more expressive
and context-aware video grounding. DualGround achieves state-of-the-art
performance on both Moment Retrieval and Highlight Detection tasks across
QVHighlights and Charades- STA benchmarks, demonstrating the effectiveness of
disentangled semantic modeling in video-language alignment.

- **Convexity of Neural Codes with Four Maximal Codewords**
  - 发表日期：2025-10-23 | 推荐度：0.828 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20323v1
  - 摘要：Place cells are neurons that act as biological position sensors, associated
with and firing in response to regions of an environment to situate an organism
in space. These associations are recorded in (combinatorial) neural codes,
motivating the following mathematical question: Which neural codes are
generated by a collection of convex open sets in Euclidean space? Giusti and
Itskov showed that a necessary condition for convexity is the absence of
``local obstructions." This necessary condition is, in fact, sufficient for
certain families of codes. One such family consists of all codes with up to
three maximal codewords. In this article, we investigate codes with four
maximal codewords, showing that for many such codes, convexity is characterized
by the absence of local obstructions, whereas for other such codes, convexity
is characterized by the absence of local obstructions and a second type of
obstruction, a ``wheel". Key to our analysis is a case-by-case investigation
based on the nerve complex of the set of maximal codewords of a neural code. Up
to symmetry, there are 20 possible nerves; and our results fully characterize
convexity in 15 of the 20 cases.

- **EmbodiedBrain: Expanding Performance Boundaries of Task Planning for
  Embodied Intelligence**
  - 发表日期：2025-10-23 | 推荐度：0.828 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20578v1
  - 摘要：The realization of Artificial General Intelligence (AGI) necessitates
Embodied AI agents capable of robust spatial perception, effective task
planning, and adaptive execution in physical environments. However, current
large language models (LLMs) and multimodal LLMs (MLLMs) for embodied tasks
suffer from key limitations, including a significant gap between model design
and agent requirements, an unavoidable trade-off between real-time latency and
performance, and the use of unauthentic, offline evaluation metrics. To address
these challenges, we propose EmbodiedBrain, a novel vision-language foundation
model available in both 7B and 32B parameter sizes. Our framework features an
agent-aligned data structure and employs a powerful training methodology that
integrates large-scale Supervised Fine-Tuning (SFT) with Step-Augumented Group
Relative Policy Optimization (Step-GRPO), which boosts long-horizon task
success by integrating preceding steps as Guided Precursors. Furthermore, we
incorporate a comprehensive reward system, including a Generative Reward Model
(GRM) accelerated at the infrastructure level, to improve training efficiency.
For enable thorough validation, we establish a three-part evaluation system
encompassing General, Planning, and End-to-End Simulation Benchmarks,
highlighted by the proposal and open-sourcing of a novel, challenging
simulation environment. Experimental results demonstrate that EmbodiedBrain
achieves superior performance across all metrics, establishing a new
state-of-the-art for embodied foundation models. Towards paving the way for the
next generation of generalist embodied agents, we open-source all of our data,
model weight, and evaluating methods, which are available at
https://zterobot.github.io/EmbodiedBrain.github.io.

- **Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role
  of Context**
  - 发表日期：2025-10-23 | 推荐度：0.827 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20229v1
  - 摘要：Large Vision-Language Models (LVLMs) have made significant progress in recent
years but are also prone to hallucination issues. They exhibit more
hallucinations in longer, free-form responses, often attributed to accumulated
uncertainties. In this paper, we ask: Does increased hallucination result
solely from length-induced errors, or is there a deeper underlying mechanism?
After a series of preliminary experiments and findings, we suggest that the
risk of hallucinations is not caused by length itself but by the increased
reliance on context for coherence and completeness in longer responses.
Building on these insights, we propose a novel "induce-detect-suppress"
framework that actively induces hallucinations through deliberately designed
contexts, leverages induced instances for early detection of high-risk cases,
and ultimately suppresses potential object-level hallucinations during actual
decoding. Our approach achieves consistent, significant improvements across all
benchmarks, demonstrating its efficacy. The strong detection and improved
hallucination mitigation not only validate our framework but, more importantly,
re-validate our hypothesis on context. Rather than solely pursuing performance
gains, this study aims to provide new insights and serves as a first step
toward a deeper exploration of hallucinations in LVLMs' longer responses.

- **LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning
  Framework for Recommender Systems**
  - 发表日期：2025-10-23 | 推荐度：0.827 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20327v1
  - 摘要：With the growing demand for safeguarding sensitive user information in
recommender systems, recommendation attribute unlearning is receiving
increasing attention. Existing studies predominantly focus on single-attribute
unlearning. However, privacy protection requirements in the real world often
involve multiple sensitive attributes and are dynamic. Existing
single-attribute unlearning methods cannot meet these real-world requirements
due to i) CH1: the inability to handle multiple unlearning requests
simultaneously, and ii) CH2: the lack of efficient adaptability to dynamic
unlearning needs. To address these challenges, we propose LEGO, a lightweight
and efficient multiple-attribute unlearning framework. Specifically, we divide
the multiple-attribute unlearning process into two steps: i) Embedding
Calibration removes information related to a specific attribute from user
embedding, and ii) Flexible Combination combines these embeddings into a single
embedding, protecting all sensitive attributes. We frame the unlearning process
as a mutual information minimization problem, providing LEGO a theoretical
guarantee of simultaneous unlearning, thereby addressing CH1. With the two-step
framework, where Embedding Calibration can be performed in parallel and
Flexible Combination is flexible and efficient, we address CH2. Extensive
experiments on three real-world datasets across three representative
recommendation models demonstrate the effectiveness and efficiency of our
proposed framework. Our code and appendix are available at
https://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.

- **Optimal constant-cost implementations of Clifford operations using
  global interactions**
  - 发表日期：2025-10-23 | 推荐度：0.826 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20730v1
  - 摘要：We investigate quantum circuits built from arbitrary single-qubit operations
combined with programmable all-to-all multiqubit entangling gates that are
native to, among other systems, trapped-ion quantum computing platforms. We
report a constant-cost of no more than four applications of such Clifford
entangling multiqubit gates to realize any sequence of Clifford operations of
any length, without ancillae, which is the theoretically optimal gate count
cost. We do this by implementing any sequence of CNOT gates of any length with
four applications of such gates, without ancillae, and show that the extension
to general Clifford operations incurs no additional cost. We investigate the
required qubit drive power that is associated with our implementation and show
that it is lower than that of a standard approach. Our work introduces a
practical and computationally efficient algorithm to realize these
compilations.

- **New Second-Order Achievability Bounds for Coding with Side Information
  via Type Deviation Convergence**
  - 发表日期：2025-10-23 | 推荐度：0.826 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20241v1
  - 摘要：We propose a framework for second-order achievability, called type deviation
convergence, that is generally applicable to settings in network information
theory, and is especially suitable for lossy source coding and channel coding
with cost. We give a second-order achievability bound for lossy source coding
with side information at the decoder (Wyner-Ziv problem) that improves upon all
known bounds (e.g., Watanabe-Kuzuoka-Tan, Yassaee-Aref-Gohari and
Li-Anantharam). We also give second-order achievability bounds for lossy
compression where side information may be absent (Heegard-Berger problem) and
channels with noncausal state information at the encoder and cost constraint
(Gelfand-Pinsker problem with cost) that improve upon previous bounds.

- **Analyticup E-commerce Product Search Competition Technical Report from
  Team Tredence_AICOE**
  - 发表日期：2025-10-23 | 推荐度：0.826 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20674v1
  - 摘要：This study presents the multilingual e-commerce search system developed by
the Tredence_AICOE team. The competition features two multilingual relevance
tasks: Query-Category (QC) Relevance, which evaluates how well a user's search
query aligns with a product category, and Query-Item (QI) Relevance, which
measures the match between a multilingual search query and an individual
product listing. To ensure full language coverage, we performed data
augmentation by translating existing datasets into languages missing from the
development set, enabling training across all target languages. We fine-tuned
Gemma-3 12B and Qwen-2.5 14B model for both tasks using multiple strategies.
The Gemma-3 12B (4-bit) model achieved the best QC performance using original
and translated data, and the best QI performance using original, translated,
and minority class data creation. These approaches secured 4th place on the
final leaderboard, with an average F1-score of 0.8857 on the private test set.

- **Resource-Aware Hybrid Quantum Programming with General Recursion and
  Quantum Control**
  - 发表日期：2025-10-23 | 推荐度：0.825 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20452v1
  - 摘要：This paper introduces the hybrid quantum language with general recursion
$\mathtt{Hyrql}$, driven towards resource-analysis. By design, $\mathtt{Hyrql}$
does not require the specification of an initial set of quantum gates and,
hence, is well amenable towards a generic cost analysis. Indeed, languages
using different sets of quantum gates lead to representations of quantum
circuits whose complexity varies. Towards resource-analysis, a
semantics-preserving compilation algorithm to simply-typed term rewrite systems
is described; allowing a generic reuse of all known techniques for analyzing
the complexity of term rewrite systems. We prove the versatility of this
approach through many examples.

- **Real Deep Research for AI, Robotics and Beyond**
  - 发表日期：2025-10-23 | 推荐度：0.825 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20809v1
  - 摘要：With the rapid growth of research in AI and robotics now producing over
10,000 papers annually it has become increasingly difficult for researchers to
stay up to date. Fast evolving trends, the rise of interdisciplinary work, and
the need to explore domains beyond one's expertise all contribute to this
challenge. To address these issues, we propose a generalizable pipeline capable
of systematically analyzing any research area: identifying emerging trends,
uncovering cross domain opportunities, and offering concrete starting points
for new inquiry. In this work, we present Real Deep Research (RDR) a
comprehensive framework applied to the domains of AI and robotics, with a
particular focus on foundation models and robotics advancements. We also
briefly extend our analysis to other areas of science. The main paper details
the construction of the RDR pipeline, while the appendix provides extensive
results across each analyzed topic. We hope this work sheds light for
researchers working in the field of AI and beyond.

- **NeuPerm: Disrupting Malware Hidden in Neural Network Parameters by
  Leveraging Permutation Symmetry**
  - 发表日期：2025-10-23 | 推荐度：0.825 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20367v1
  - 摘要：Pretrained deep learning model sharing holds tremendous value for researchers
and enterprises alike. It allows them to apply deep learning by fine-tuning
models at a fraction of the cost of training a brand-new model. However, model
sharing exposes end-users to cyber threats that leverage the models for
malicious purposes. Attackers can use model sharing by hiding self-executing
malware inside neural network parameters and then distributing them for
unsuspecting users to unknowingly directly execute them, or indirectly as a
dependency in another software. In this work, we propose NeuPerm, a simple yet
effec- tive way of disrupting such malware by leveraging the theoretical
property of neural network permutation symmetry. Our method has little to no
effect on model performance at all, and we empirically show it successfully
disrupts state-of-the-art attacks that were only previously addressed using
quantization, a highly complex process. NeuPerm is shown to work on LLMs, a
feat that no other previous similar works have achieved. The source code is
available at https://github.com/danigil/NeuPerm.git.

- **NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew**
  - 发表日期：2025-10-23 | 推荐度：0.825 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20386v1
  - 摘要：Since their initial release, BERT models have demonstrated exceptional
performance on a variety of tasks, despite their relatively small size
(BERT-base has ~100M parameters). Nevertheless, the architectural choices used
in these models are outdated compared to newer transformer-based models such as
Llama3 and Qwen3. In recent months, several architectures have been proposed to
close this gap. ModernBERT and NeoBERT both show strong improvements on English
benchmarks and significantly extend the supported context window. Following
their successes, we introduce NeoDictaBERT and NeoDictaBERT-bilingual:
BERT-style models trained using the same architecture as NeoBERT, with a
dedicated focus on Hebrew texts. These models outperform existing ones on
almost all Hebrew benchmarks and provide a strong foundation for downstream
tasks. Notably, the NeoDictaBERT-bilingual model shows strong results on
retrieval tasks, outperforming other multilingual models of similar size. In
this paper, we describe the training process and report results across various
benchmarks. We release the models to the community as part of our goal to
advance research and development in Hebrew NLP.

- **PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast
  Cancer Detection**
  - 发表日期：2025-10-23 | 推荐度：0.824 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20611v1
  - 摘要：Breast cancer is considered the most critical and frequently diagnosed cancer
in women worldwide, leading to an increase in cancer-related mortality. Early
and accurate detection is crucial as it can help mitigate possible threats
while improving survival rates. In terms of prediction, conventional diagnostic
methods are often limited by variability, cost, and, most importantly, risk of
misdiagnosis. To address these challenges, machine learning (ML) has emerged as
a powerful tool for computer-aided diagnosis, with feature selection playing a
vital role in improving model performance and interpretability. This research
study proposes an integrated framework that incorporates customized Particle
Swarm Optimization (PSO) for feature selection. This framework has been
evaluated on a comprehensive set of 29 different models, spanning classical
classifiers, ensemble techniques, neural networks, probabilistic algorithms,
and instance-based algorithms. To ensure interpretability and clinical
relevance, the study uses cross-validation in conjunction with explainable AI
methods. Experimental evaluation showed that the proposed approach achieved a
superior score of 99.1\% across all performance metrics, including accuracy and
precision, while effectively reducing dimensionality and providing transparent,
model-agnostic explanations. The results highlight the potential of combining
swarm intelligence with explainable ML for robust, trustworthy, and clinically
meaningful breast cancer diagnosis.

- **Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents**
  - 发表日期：2025-10-23 | 推荐度：0.824 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20211v1
  - 摘要：Cloud infrastructure is managed through a mix of interfaces -- traditionally,
cloud consoles, command-line interfaces (CLI), and SDKs are the tools of
choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have
quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the
infrastructure in a "source-of-truth" configuration. They are capable of
automatically carrying out modifications to the cloud -- deploying, updating,
or destroying resources -- to bring the actual infrastructure into alignment
with the IaC configuration. However, when IaC is used alongside consoles, CLIs,
or SDKs, it loses visibility into external changes, causing infrastructure
drift, where the configuration becomes outdated, and later IaC operations may
undo valid updates or trigger errors.
  We present NSync, an automated system for IaC reconciliation that propagates
out-of-band changes back into the IaC program. Our key insight is that
infrastructure changes eventually all occur via cloud API invocations -- the
lowest layer for cloud management operations. NSync gleans insights from API
traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update
the IaC configuration to capture the changes). It employs an agentic
architecture that leverages LLMs to infer high-level intents from noisy API
sequences, synthesize targeted IaC updates using specialized tools, and
continually improve through a self-evolving knowledge base of past
reconciliations. We further introduce a novel evaluation pipeline for injecting
realistic drifts into cloud infrastructure and assessing reconciliation
performance. Experiments across five real-world Terraform projects and 372
drift scenarios show that NSync outperforms the baseline both in terms of
accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\times$
improvement).

- **Trust, But Verify: An Empirical Evaluation of AI-Generated Code for SDN
  Controllers**
  - 发表日期：2025-10-23 | 推荐度：0.823 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20703v1
  - 摘要：Generative Artificial Intelligence (AI) tools have been used to generate
human-like content across multiple domains (e.g., sound, image, text, and
programming). However, their reliability in terms of correctness and
functionality in novel contexts such as programmable networks remains unclear.
Hence, this paper presents an empirical evaluation of the source code of a POX
controller generated by different AI tools, namely ChatGPT, Copilot, DeepSeek,
and BlackBox.ai. To evaluate such a code, three networking tasks of increasing
complexity were defined and for each task, zero-shot and few-shot prompting
techniques were input to the tools. Next, the output code was tested in
emulated network topologies with Mininet and analyzed according to
functionality, correctness, and the need for manual fixes. Results show that
all evaluated models can produce functional controllers. However, ChatGPT and
DeepSeek exhibited higher consistency and code quality, while Copilot and
BlackBox.ai required more adjustments.

- **Incomplete U-Statistics of Equireplicate Designs: Berry-Esseen Bound and
  Efficient Construction**
  - 发表日期：2025-10-23 | 推荐度：0.822 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20755v1
  - 摘要：U-statistics are a fundamental class of estimators that generalize the sample
mean and underpin much of nonparametric statistics. Although extensively
studied in both statistics and probability, key challenges remain: their high
computational cost - addressed partly through incomplete U-statistics - and
their non-standard asymptotic behavior in the degenerate case, which typically
requires resampling methods for hypothesis testing. This paper presents a novel
perspective on U-statistics, grounded in hypergraph theory and combinatorial
designs. Our approach bypasses the traditional Hoeffding decomposition, the
main analytical tool in this literature but one highly sensitive to degeneracy.
By characterizing the dependence structure of a U-statistic, we derive a
Berry-Esseen bound that applies to all incomplete U-statistics of deterministic
designs, yielding conditions under which Gaussian limiting distributions can be
established even in the degenerate case and when the order diverges. We also
introduce efficient algorithms to construct incomplete U-statistics of
equireplicate designs, a subclass of deterministic designs that, in certain
cases, achieve minimum variance. Finally, we apply our framework to
kernel-based tests that use Maximum Mean Discrepancy (MMD) and Hilbert-Schmidt
Independence Criterion. In a real data example with CIFAR-10, our
permutation-free MMD test delivers substantial computational gains while
retaining power and type I error control.

- **Amplifying Prominent Representations in Multimodal Learning via
  Variational Dirichlet Process**
  - 发表日期：2025-10-23 | 推荐度：0.820 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20736v1
  - 摘要：Developing effective multimodal fusion approaches has become increasingly
essential in many real-world scenarios, such as health care and finance. The
key challenge is how to preserve the feature expressiveness in each modality
while learning cross-modal interactions. Previous approaches primarily focus on
the cross-modal alignment, while over-emphasis on the alignment of marginal
distributions of modalities may impose excess regularization and obstruct
meaningful representations within each modality. The Dirichlet process (DP)
mixture model is a powerful Bayesian non-parametric method that can amplify the
most prominent features by its richer-gets-richer property, which allocates
increasing weights to them. Inspired by this unique characteristic of DP, we
propose a new DP-driven multimodal learning framework that automatically
achieves an optimal balance between prominent intra-modal representation
learning and cross-modal alignment. Specifically, we assume that each modality
follows a mixture of multivariate Gaussian distributions and further adopt DP
to calculate the mixture weights for all the components. This paradigm allows
DP to dynamically allocate the contributions of features and select the most
prominent ones, leveraging its richer-gets-richer property, thus facilitating
multimodal feature fusion. Extensive experiments on several multimodal datasets
demonstrate the superior performance of our model over other competitors.
Ablation analysis further validates the effectiveness of DP in aligning
modality distributions and its robustness to changes in key hyperparameters.
Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git

- **Co-Designing Quantum Codes with Transversal Diagonal Gates via
  Multi-Agent Systems**
  - 发表日期：2025-10-23 | 推荐度：0.819 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20728v1
  - 摘要：We present a multi-agent, human-in-the-loop workflow that co-designs quantum
codes with prescribed transversal diagonal gates. It builds on the Subset-Sum
Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis
strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL)
equalities via small LPs. The workflow is powered by GPT-5 and implemented
within TeXRA (https://texra.ai)-a multi-agent research assistant platform that
supports an iterative tool-use loop agent and a derivation-then-edit workflow
reasoning agent. We work in a LaTeX-Python environment where agents reason,
edit documents, execute code, and synchronize their work to Git/Overleaf.
Within this workspace, three roles collaborate: a Synthesis Agent formulates
the problem; a Search Agent sweeps/screens candidates and exactifies numerics
into rationals; and an Audit Agent independently checks all KL equalities and
the induced logical action. As a first step we focus on distance $d=2$ with
nondegenerate residues. For code dimension $K\in\{2,3,4\}$ and $n\le6$ qubits,
systematic sweeps yield certificate-backed tables cataloging attainable cyclic
logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$
at $n=6$. From verified instances, Synthesis Agent abstracts recurring
structures into closed-form families and proves they satisfy the KL equalities
for all parameters. It further demonstrates that SSLP accommodates residue
degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal
controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts
diagonal-transversal feasibility as an analytical pipeline executed at scale,
combining systematic enumeration with exact analytical reconstruction. It
yields reproducible code constructions, supports targeted extensions to larger
$K$ and higher distances, and leads toward data-driven classification.

- **Lens Model Accuracy in the Expected LSST Lensed AGN Sample**
  - 发表日期：2025-10-23 | 推荐度：0.818 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20778v1
  - 摘要：Strong gravitational lensing of active galactic nuclei (AGN) enables
measurements of cosmological parameters through time-delay cosmography (TDC).
With data from the upcoming LSST survey, we anticipate using a sample of
O(1000) lensed AGN for TDC. To prepare for this dataset and enable this
measurement, we construct and analyze a realistic mock sample of 1300 systems
drawn from the OM10 (Oguri & Marshall 2010) catalog of simulated lenses with
AGN sources at $z<3.1$ in order to test a key aspect of the analysis pipeline,
that of the lens modeling. We realize the lenses as power law elliptical mass
distributions and simulate 5-year LSST i-band coadd images. From every image,
we infer the lens mass model parameters using neural posterior estimation
(NPE). Focusing on the key model parameters, $\theta_E$ (the Einstein Radius)
and $\gamma_{lens}$ (the projected mass density profile slope), with consistent
mass-light ellipticity correlations in test and training data, we recover
$\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and
$\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find
that lens light subtraction prior to modeling is only useful when applied to
data sampled from the training prior. If emulated deconvolution is applied to
the data prior to modeling, precision improves across all parameters by a
factor of 2. Finally, we combine the inferred lens mass models using Bayesian
Hierarchical Inference to recover the global properties of the lens sample with
less than 1% bias.

- **A Coherence-Based Measure of AGI**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20784v1
  - 摘要：Recent work by \citet{hendrycks2025agidefinition} formalized
\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of
proficiencies across cognitive domains derived from the Cattell--Horn--Carroll
(CHC) model of human cognition. While elegant, this definition assumes
\textit{compensability} -- that exceptional ability in some domains can offset
failure in others. True general intelligence, however, should reflect
\textit{coherent sufficiency}: balanced competence across all essential
domains. We propose a coherence-aware measure of AGI based on the integral of
generalized means over a continuum of compensability exponents. This
formulation spans arithmetic, geometric, and harmonic regimes, and the
resulting \textit{area under the curve} (AUC) quantifies robustness under
varying compensability assumptions. Unlike the arithmetic mean, which rewards
specialization, the AUC penalizes imbalance and captures inter-domain
dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,
the coherence-adjusted AUC reveals that both systems remain far from general
competence despite high arithmetic scores (e.g., GPT-5 at~24\%). Integrating
the generalized mean thus yields a principled, interpretable, and stricter
foundation for measuring genuine progress toward AGI.

- **Thought Communication in Multiagent Collaboration**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20733v1
  - 摘要：Natural language has long enabled human cooperation, but its lossy,
ambiguous, and indirect nature limits the potential of collective intelligence.
While machines are not subject to these constraints, most LLM-based multi-agent
systems still rely solely on natural language, exchanging tokens or their
embeddings. To go beyond language, we introduce a new paradigm, thought
communication, which enables agents to interact directly mind-to-mind, akin to
telepathy. To uncover these latent thoughts in a principled way, we formalize
the process as a general latent variable model, where agent states are
generated by an unknown function of underlying thoughts. We prove that, in a
nonparametric setting without auxiliary information, both shared and private
latent thoughts between any pair of agents can be identified. Moreover, the
global structure of thought sharing, including which agents share which
thoughts and how these relationships are structured, can also be recovered with
theoretical guarantees. Guided by the established theory, we develop a
framework that extracts latent thoughts from all agents prior to communication
and assigns each agent the relevant thoughts, along with their sharing
patterns. This paradigm naturally extends beyond LLMs to all modalities, as
most observational data arise from hidden generative processes. Experiments on
both synthetic and real-world benchmarks validate the theory and demonstrate
the collaborative advantages of thought communication. We hope this work
illuminates the potential of leveraging the hidden world, as many challenges
remain unsolvable through surface-level observation alone, regardless of
compute or data scale.

- **Convergence Analysis of SGD under Expected Smoothness**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20608v1
  - 摘要：Stochastic gradient descent (SGD) is the workhorse of large-scale learning,
yet classical analyses rely on assumptions that can be either too strong
(bounded variance) or too coarse (uniform noise). The expected smoothness (ES)
condition has emerged as a flexible alternative that ties the second moment of
stochastic gradients to the objective value and the full gradient. This paper
presents a self-contained convergence analysis of SGD under ES. We (i) refine
ES with interpretations and sampling-dependent constants; (ii) derive bounds of
the expectation of squared full gradient norm; and (iii) prove $O(1/K)$ rates
with explicit residual errors for various step-size schedules. All proofs are
given in full detail in the appendix. Our treatment unifies and extends recent
threads (Khaled and Richt\'arik, 2020; Umeda and Iiduka, 2025).

- **Multicast-partitioning in Time-triggered Stream Planning for
  Time-Sensitive Networks**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20440v1
  - 摘要：Multicast allows sending a message to multiple recipients without having to
create and send a separate message for each recipient. This preserves network
bandwidth, which is particularly important in time-sensitive networks. These
networks are commonly used to provide latency-bounded communication for
real-time systems in domains like automotive, avionics, industrial internet of
things, automated shop floors, and smart energy grids. The preserved bandwidth
can be used to admit additional real-time messages with specific quality of
service requirements or to reduce the end-to-end latencies for messages of any
type. However, using multicast communication can complicate traffic planning,
as it requires free queues or available downstream egress ports on all branches
of the multicast tree. In this work, we present a novel multicast partitioning
technique to split multicast trees into smaller multicast or unicast trees.
This allows for a more fine-grained trade-off between bandwidth utilization and
traffic scheduling difficulty. Thus, schedulability in dynamic systems can be
improved, in terms the number of admitted streams and the accumulated network
throughput. We evaluated the multicast partitioning on different network
topologies and with three different scheduling algorithms. With the
partitioning, 5-15\% fewer streams were rejected, while achieving 5-125\% more
network throughput, depending on the scheduling algorithm.

- **Efficient Algorithms for Computing Random Walk Centrality**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：10.1109/TKDE.2025.3621520
  - 链接：http://arxiv.org/abs/2510.20604v1
  - 摘要：Random walk centrality is a fundamental metric in graph mining for
quantifying node importance and influence, defined as the weighted average of
hitting times to a node from all other nodes. Despite its ability to capture
rich graph structural information and its wide range of applications, computing
this measure for large networks remains impractical due to the computational
demands of existing methods. In this paper, we present a novel formulation of
random walk centrality, underpinning two scalable algorithms: one leveraging
approximate Cholesky factorization and sparse inverse estimation, while the
other sampling rooted spanning trees. Both algorithms operate in near-linear
time and provide strong approximation guarantees. Extensive experiments on
large real-world networks, including one with over 10 million nodes,
demonstrate the efficiency and approximation quality of the proposed
algorithms.

- **Rediscovering Recurring Routing Results**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20297v1
  - 摘要：Routing is central to networking performance, including: (1) latency in
anycast services and websites served from multiple locations,(2) networking
expenses and throughput in multi-homed enterprises, (3) the ability to keep
traffic domestic when considering data sovereignty. However, understanding and
managing how routing affects these services is challenging. Operators use
Traffic Engineering (TE) with BGP to optimize network performance, but what
they get is the result of all BGP policies throughout the Internet, not just
their local choices. Our paper proposes Fenrir, a new system to rediscover
recurring routing results. Fenrir can discover changes in network routing, even
when it happens multiple hops away from the observer. Fenrir also provides new
methods to quantify the degree of routing change, and to identify routing
"modes" that may reappear. Second, we show that Fenrir can be applied to many
different problems: we use five instances of three different types of systems
to illustrate the generalization: anycast catchments showing in a root DNS
service, route optimization for two multi-homed enterprises, and website
selection for two of the top-10 web services. Each type requires different
types of active measurements, data cleaning and weighting. We demonstrate
Fenrir's methods of detecting and quantifying change are helpful because they
all face similar operational questions: How much effect did traffic engineering
have? Did a third-party change alter my routing? In either case, is the current
routing new, or is it like a routing mode I saw before?

- **SafeFFI: Efficient Sanitization at the Boundary Between Safe and Unsafe
  Code in Rust and Mixed-Language Applications**
  - 发表日期：2025-10-23 | 推荐度：0.816 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20688v1
  - 摘要：Unsafe Rust code is necessary for interoperability with C/C++ libraries and
implementing low-level data structures, but it can cause memory safety
violations in otherwise memory-safe Rust programs. Sanitizers can catch such
memory errors at runtime, but introduce many unnecessary checks even for memory
accesses guaranteed safe by the Rust type system. We introduce SafeFFI, a
system for optimizing memory safety instrumentation in Rust binaries such that
checks occur at the boundary between unsafe and safe code, handing over the
enforcement of memory safety from the sanitizer to the Rust type system. Unlike
previous approaches, our design avoids expensive whole-program analysis and
adds much less compile-time overhead (2.64x compared to over 8.83x). On a
collection of popular Rust crates and known vulnerable Rust code, SafeFFI
achieves superior performance compared to state-of-the-art systems, reducing
sanitizer checks by up to 98%, while maintaining correctness and flagging all
spatial and temporal memory safety violations.

- **Balanced Popularity in Multi-Product Billboard Advertisement**
  - 发表日期：2025-10-23 | 推荐度：0.815 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20600v1
  - 摘要：The billboard advertisement has emerged as an effective out-of-home
advertisement technique where the objective is to choose a limited number of
slots to play some advertisement content (e.g., animation, video, etc.) with
the hope that the content will be visible to a large number of travelers, and
this will be helpful to earn more revenue. In this paper, we study a variant of
the influential slot selection problem where the advertiser wants to promote
multiple products. Formally, we call this problem the \textsc{Multi-Product
Influence Maximization Problem for the Balanced Popularity} Problem. The input
to our problem is a trajectory and a billboard database, as well as a budget
for each product. The goal here is to choose a subset of slots for each product
such that the aggregated influence of all the products gets maximized subject
to the following two constraints: total selection cost for each product is less
than or equal to the allocated budget for that product, and the difference
between the influence for any two products is less than or equal to a given
threshold. We show that the problem is NP-hard to solve optimally. We formulate
this problem as a linear programming problem and use linear programming
relaxation with randomized rounding. Further, we propose a greedy-based
heuristic with balance correction to solve this problem. We conduct a number of
experiments with real-world trajectory and billboard datasets, and the results
are reported. From the reported results, we observe that the proposed solution
approaches lead to more influence compared to many baseline methods.

- **SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models
  for Time Series**
  - 发表日期：2025-10-23 | 推荐度：0.815 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20273v1
  - 摘要：Recent advances in deep learning have driven rapid progress in time series
forecasting, yet many state-of-the-art models continue to struggle with robust
performance in real-world applications, even when they achieve strong results
on standard benchmark datasets. This persistent gap can be attributed to the
black-box nature of deep learning architectures and the inherent limitations of
current evaluation frameworks, which frequently lack the capacity to provide
clear, quantitative insights into the specific strengths and weaknesses of
different models, thereby complicating the selection of appropriate models for
particular forecasting scenarios. To address these issues, we propose a
synthetic data-driven evaluation paradigm, SynTSBench, that systematically
assesses fundamental modeling capabilities of time series forecasting models
through programmable feature configuration. Our framework isolates confounding
factors and establishes an interpretable evaluation system with three core
analytical dimensions: (1) temporal feature decomposition and capability
mapping, which enables systematic evaluation of model capacities to learn
specific pattern types; (2) robustness analysis under data irregularities,
which quantifies noise tolerance thresholds and anomaly recovery capabilities;
and (3) theoretical optimum benchmarking, which establishes performance
boundaries for each pattern type-enabling direct comparison between model
predictions and mathematical optima. Our experiments show that current deep
learning models do not universally approach optimal baselines across all types
of temporal features.The code is available at
https://github.com/TanQitai/SynTSBench

- **A comparison of methods for designing hybrid type 2 cluster-randomized
  trials with continuous effectiveness and implementation endpoints**
  - 发表日期：2025-10-23 | 推荐度：0.814 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20741v1
  - 摘要：Hybrid type 2 studies are gaining popularity for their ability to assess both
implementation and health outcomes as co-primary endpoints. Often conducted as
cluster-randomized trials (CRTs), five design methods can validly power these
studies: p-value adjustment methods, combined outcomes approach, single
weighted 1-DF test, disjunctive 2-DF test, and conjunctive test. We compared
all of the methods theoretically and numerically. Theoretical comparisons of
the power equations allowed us to identify if any method globally had more or
less power than other methods. It was shown that the p-value adjustment methods
are always less powerful than the combined outcomes approach and the single
1-DF test. We also identified the conditions under which the disjunctive 2-DF
test is less powerful than the single 1-DF test. Because our theoretical
comparison showed that some methods could be more powerful than others under
certain conditions, and less powerful under others, we conducted a numerical
study to understand these differences. The crt2power R package was created to
calculate the power or sample size for CRTs with two continuous co-primary
endpoints. Using this package, we conducted a numerical evaluation across
30,000 input scenarios to compare statistical power. Specific patterns were
identified where a certain method consistently achieved the highest power. When
the treatment effects are unequal, the disjunctive 2-DF test tends to have
higher power. When the treatment effect sizes are the same, the single 1-DF
test tends to have higher power. Together, these comparisons provide clearer
insights to guide method selection for powering hybrid type 2 studies.

- **Learning to Triage Taint Flows Reported by Dynamic Program Analysis in
  Node.js Packages**
  - 发表日期：2025-10-23 | 推荐度：0.813 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20739v1
  - 摘要：Program analysis tools often produce large volumes of candidate vulnerability
reports that require costly manual review, creating a practical challenge: how
can security analysts prioritize the reports most likely to be true
vulnerabilities?
  This paper investigates whether machine learning can be applied to
prioritizing vulnerabilities reported by program analysis tools. We focus on
Node.js packages and collect a benchmark of 1,883 Node.js packages, each
containing one reported ACE or ACI vulnerability. We evaluate a variety of
machine learning approaches, including classical models, graph neural networks
(GNNs), large language models (LLMs), and hybrid models that combine GNN and
LLMs, trained on data based on a dynamic program analysis tool's output. The
top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models
reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading
model eliminates 66.9% of benign packages from manual review, taking around 60
ms per package. If the best model is tuned to operate at a precision level of
0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can
detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating
strong potential for real-world vulnerability triage.

- **UI-Ins: Enhancing GUI Grounding with Multi-Perspective
  Instruction-as-Reasoning**
  - 发表日期：2025-10-23 | 推荐度：0.813 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20286v1
  - 摘要：GUI grounding, which maps natural-language instructions to actionable UI
elements, is a core capability of GUI agents. Prior works largely treats
instructions as a static proxy for user intent, overlooking the impact of
instruction diversity and quality on grounding performance. Through a careful
investigation of existing grounding datasets, we find a 23.3% flaw rate in
their instructions and show that inference-time exploitation of instruction
diversity yields up to a substantial 76% relative performance improvement. In
this paper, we introduce the Instruction-as-Reasoning paradigm, treating
instructions as dynamic analytical pathways that offer distinct perspectives
and enabling the model to select the most effective pathway during reasoning.
To achieve this, we propose a two-stage training framework: supervised
fine-tuning (SFT) on synthesized, diverse instructions to instill
multi-perspective reasoning, followed by reinforcement learning (RL) to
optimize pathway selection and composition. Our resulting models, UI-Ins-7B and
UI-Ins-32B, achieve state-of-the-art results on five challenging grounding
benchmarks and exhibit emergent reasoning, selectively composing and
synthesizing novel instruction pathways at inference. In particular, UI-Ins-32B
attains the best grounding accuracy, scoring 87.3% on UI-I2E-Bench, 57.0% on
ScreenSpot-Pro, and 84.9% on MMBench-GUI L2. Furthermore, our model
demonstrates strong agentic potential, achieving a 74.1% success rate on
AndroidWorld using UI-Ins-7B as the executor. Our in-depth analysis reveals
additional insights such as how reasoning can be formulated to enhance rather
than hinder grounding performance, and how our method mitigates policy collapse
in the SFT+RL framework. All code and model checkpoints will be publicly
released in https://github.com/alibaba/UI-Ins.

- **Addressing wavelength-correlated systematics in exoplanet transmission
  spectroscopy: a 2D Gaussian Process approach**
  - 发表日期：2025-10-23 | 推荐度：0.811 | 来源：arXiv
  - DOI：10.1117/12.3063572
  - 链接：http://arxiv.org/abs/2510.20423v1
  - 摘要：Ground-based transmission spectroscopy is often dominated by systematics,
which obstructs our ability to leverage the advantages of larger aperture sizes
compared to space-based observations. These systematics could be
time-correlated, uniform across all spectroscopic light curves, or
wavelength-correlated, which could significantly affect the characterization of
exoplanet atmospheres. Gaussian Processes were introduced in transmission
spectroscopy by Gibson et al. (2012) to model correlated systematics in a
non-parametric way. The technique uses auxiliary information about the
observation and independently fits each spectroscopic light curve to provide
robust atmospheric retrievals. However, this method assumes that the
uncertainties in the transmission spectrum are uncorrelated in wavelength,
which can cause discrepancies and degrade the precision of atmospheric
retrievals. To address this limitation, we explore a 2D GP framework formulated
by Fortune et al. (2024) to simultaneously model time- and
wavelength-correlated systematics. We present its application to ground-based
observations of TOI-4153b obtained using the 2-m Himalayan Chandra Telescope
(HCT). As we move towards detecting smaller and cooler planets, developing new
methods to address complex systematics becomes increasingly essential.

- **KL-Regularized Reinforcement Learning is Designed to Mode Collapse**
  - 发表日期：2025-10-23 | 推荐度：0.811 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20817v1
  - 摘要：It is commonly believed that optimizing the reverse KL divergence results in
"mode seeking", while optimizing forward KL results in "mass covering", with
the latter being preferred if the goal is to sample from multiple diverse
modes. We show -- mathematically and empirically -- that this intuition does
not necessarily transfer well to doing reinforcement learning with
reverse/forward KL regularization (e.g. as commonly used with language models).
Instead, the choice of reverse/forward KL determines the family of optimal
target distributions, parameterized by the regularization coefficient. Mode
coverage depends primarily on other factors, such as regularization strength,
and relative scales between rewards and reference probabilities. Further, we
show commonly used settings such as low regularization strength and equal
verifiable rewards tend to specify unimodal target distributions, meaning the
optimization objective is, by construction, non-diverse. We leverage these
insights to construct a simple, scalable, and theoretically justified
algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a
target distribution which puts high probability over all high-quality sampling
modes. In experiments, this simple modification works to post-train both Large
Language Models and Chemical Language Models to have higher solution quality
and diversity, without any external signals of diversity, and works with both
forward and reverse KL when using either naively fails.

- **Partial Optimality in Cubic Correlation Clustering for General Graphs**
  - 发表日期：2025-10-23 | 推荐度：0.810 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20431v1
  - 摘要：The higher-order correlation clustering problem for a graph $G$ and costs
associated with cliques of $G$ consists in finding a clustering of $G$ so as to
minimize the sum of the costs of those cliques whose nodes all belong to the
same cluster. To tackle this NP-hard problem in practice, local search
heuristics have been proposed and studied in the context of applications. Here,
we establish partial optimality conditions for cubic correlation clustering,
i.e., for the special case of at most 3-cliques. We define and implement
algorithms for deciding these conditions and examine their effectiveness
numerically, on two data sets.
