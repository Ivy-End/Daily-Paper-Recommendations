## 每日论文推荐 — 2025-10-23

- **Attentive Convolution: Unifying the Expressivity of Self-Attention with
  Convolutional Efficiency**
  - 发表日期：2025-10-23 | 推荐度：0.864 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20092v1
  - 摘要：Self-attention (SA) has become the cornerstone of modern vision backbones for
its powerful expressivity over traditional Convolutions (Conv). However, its
quadratic complexity remains a critical bottleneck for practical applications.
Given that Conv offers linear complexity and strong visual priors, continuing
efforts have been made to promote the renaissance of Conv. However, a
persistent performance chasm remains, highlighting that these modernizations
have not yet captured the intrinsic expressivity that defines SA. In this
paper, we re-examine the design of the CNNs, directed by a key question: what
principles give SA its edge over Conv? As a result, we reveal two fundamental
insights that challenge the long-standing design intuitions in prior research
(e.g., Receptive field). The two findings are: (1) \textit{Adaptive routing}:
SA dynamically regulates positional information flow according to semantic
content, whereas Conv employs static kernels uniformly across all positions.
(2) \textit{Lateral inhibition}: SA induces score competition among token
weighting, effectively suppressing redundancy and sharpening representations,
whereas Conv filters lack such inhibitory dynamics and exhibit considerable
redundancy. Based on this, we propose \textit{Attentive Convolution} (ATConv),
a principled reformulation of the convolutional operator that intrinsically
injects these principles. Interestingly, with only $3\times3$ kernels, ATConv
consistently outperforms various SA mechanisms in fundamental vision tasks.
Building on ATConv, we introduce AttNet, a CNN family that can attain
\textbf{84.4\%} ImageNet-1K Top-1 accuracy with only 27M parameters. In
diffusion-based image generation, replacing all SA with the proposed $3\times
3$ ATConv in SiT-XL/2 reduces ImageNet FID by 0.15 in 400k steps with faster
sampling. Code is available at: github.com/price112/Attentive-Convolution.

- **KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models**
  - 发表日期：2025-10-23 | 推荐度：0.852 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20278v1
  - 摘要：In recent years, Pretrained Large Models(PLMs) researchers proposed
large-small model collaboration frameworks, leveraged easily trainable small
models to assist large models, aim to(1) significantly reduce computational
resource consumption while maintaining comparable accuracy, and (2) enhance
large model performance in specialized domain tasks. However, this
collaborative paradigm suffers from issues such as significant accuracy
degradation, exacerbated catastrophic forgetting, and amplified hallucination
problems induced by small model knowledge. To address these challenges, we
propose a KAN-based Collaborative Model (KCM) as an improved approach to
large-small model collaboration. The KAN utilized in KCM represents an
alternative neural network architecture distinct from conventional MLPs.
Compared to MLPs, KAN offers superior visualizability and interpretability
while mitigating catastrophic forgetting. We deployed KCM in large-small model
collaborative systems across three scenarios: language, vision, and
vision-language cross-modal tasks. The experimental results demonstrate that,
compared with pure large model approaches, the large-small model collaboration
framework utilizing KCM as the collaborative model significantly reduces the
number of large model inference calls while maintaining near-identical task
accuracy, thereby substantially lowering computational resource consumption.
Concurrently, the KAN-based small collaborative model markedly mitigates
catastrophic forgetting, leading to significant accuracy improvements for
long-tail data. The results reveal that KCM demonstrates superior performance
across all metrics compared to MLP-based small collaborative models (MCM).

- **A Multifunctional Capacitive Sensing Platform for Wireless Vascular and
  Heart Monitoring**
  - 发表日期：2025-10-23 | 推荐度：0.848 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20415v1
  - 摘要：We present a multifunctional, antenna-integrated capacitive sensing (MAiCaS)
platform for passive, wireless, and real-time cardiovascular monitoring. Unlike
conventional systems that require separate sensors and wireless modules, our
device unifies sensing, telemetry, and mechanical functionality into a compact
and scalable design by exploiting the parasitic capacitance of an inductive
antenna as a strain-sensitive element. The sensor is fabricated using a
cleanroom-free, single-step UV laser patterning process on a flexible PDMS
substrate, reducing manufacturing complexity and enabling high reproducibility.
The MAiCaS is suitable for three different applications: as a sensor for
epicardial strain measurement, a stent as a sensor, and a vascular graft
sensor. We demonstrate MAiCaS's versatility by validating its wireless
resonance-based response to strain, pressure, and deformation across unrolled
and rolled forms. In vitro experiments demonstrated consistent resonance
frequency shifts under physiological conditions, with stable performance on
skin, in PBS, human serum, and simulated vascular environments. Repeatability
and aging tests confirmed its long-term reliability and elasticity under cyclic
loading. Calibration curves revealed high sensitivity across all
configurations, with wireless interrogation achieved through S11 parameter
measurements and resonance frequency shift as the output metric. The
sensitivity of the device was measured to be 2.9 MHz per 1% strain, 0.43
MHz/mmHg, and 309.6kHz/\textmu m for epicardial patch, graft, and stent
integrated sensor, respectively. The operation of MAiCaS was evaluated in a
human experiment. This monolithic sensor architecture provides a scalable and
cost-effective solution for battery-free monitoring of vascular dynamics, with
potential for remote diagnostics, post-surgical follow-up, and continuous
cardiovascular health management.

- **SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal
  Alignment**
  - 发表日期：2025-10-23 | 推荐度：0.845 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20540v1
  - 摘要：Conventional multimodal alignment methods assume mutual redundancy across all
modalities, an assumption that fails in real-world distributed scenarios. We
propose SheafAlign, a sheaf-theoretic framework for decentralized multimodal
alignment that replaces single-space alignment with multiple comparison spaces.
This approach models pairwise modality relations through sheaf structures and
leverages decentralized contrastive learning-based objectives for training.
SheafAlign overcomes the limitations of prior methods by not requiring mutual
redundancy among all modalities, preserving both shared and unique information.
Experiments on multimodal sensing datasets show superior zero-shot
generalization, cross-modal alignment, and robustness to missing modalities,
with 50\% lower communication cost than state-of-the-art baselines.

- **Synthetic Data for Robust Runway Detection**
  - 发表日期：2025-10-23 | 推荐度：0.844 | 来源：arXiv
  - DOI：10.1007/978-3-032-04968-1_25
  - 链接：http://arxiv.org/abs/2510.20349v1
  - 摘要：Deep vision models are now mature enough to be integrated in industrial and
possibly critical applications such as autonomous navigation. Yet, data
collection and labeling to train such models requires too much efforts and
costs for a single company or product. This drawback is more significant in
critical applications, where training data must include all possible conditions
including rare scenarios. In this perspective, generating synthetic images is
an appealing solution, since it allows a cheap yet reliable covering of all the
conditions and environments, if the impact of the synthetic-to-real
distribution shift is mitigated. In this article, we consider the case of
runway detection that is a critical part in autonomous landing systems
developed by aircraft manufacturers. We propose an image generation approach
based on a commercial flight simulator that complements a few annotated real
images. By controlling the image generation and the integration of real and
synthetic data, we show that standard object detection models can achieve
accurate prediction. We also evaluate their robustness with respect to adverse
conditions, in our case nighttime images, that were not represented in the real
data, and show the interest of using a customized domain adaptation strategy.

- **In-DRAM True Random Number Generation Using Simultaneous Multiple-Row
  Activation: An Experimental Study of Real DRAM Chips**
  - 发表日期：2025-10-23 | 推荐度：0.844 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20269v1
  - 摘要：In this work, we experimentally demonstrate that it is possible to generate
true random numbers at high throughput and low latency in commercial
off-the-shelf (COTS) DRAM chips by leveraging simultaneous multiple-row
activation (SiMRA) via an extensive characterization of 96 DDR4 DRAM chips. We
rigorously analyze SiMRA's true random generation potential in terms of
entropy, latency, and throughput for varying numbers of simultaneously
activated DRAM rows (i.e., 2, 4, 8, 16, and 32), data patterns, temperature
levels, and spatial variations. Among our 11 key experimental observations, we
highlight four key results. First, we evaluate the quality of our TRNG designs
using the commonly-used NIST statistical test suite for randomness and find
that all SiMRA-based TRNG designs successfully pass each test. Second, 2-, 8-,
16-, and 32-row activation-based TRNG designs outperform the state-of-theart
DRAM-based TRNG in throughput by up to 1.15x, 1.99x, 1.82x, and 1.39x,
respectively. Third, SiMRA's entropy tends to increase with the number of
simultaneously activated DRAM rows. Fourth, operational parameters and
conditions (e.g., data pattern and temperature) significantly affect entropy.
For example, for most of the tested modules, the average entropy of 32-row
activation is 2.51x higher than that of 2-row activation. For example,
increasing the temperature from 50{\deg}C to 90{\deg}C decreases SiMRA's
entropy by 1.53x for 32-row activation. To aid future research and development,
we open-source our infrastructure at https://github.com/CMU-SAFARI/SiMRA-TRNG.

- **Downsizing Diffusion Models for Cardinality Estimation**
  - 发表日期：2025-10-23 | 推荐度：0.841 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20681v1
  - 摘要：Inspired by the performance of score-based diffusion models in estimating
complex text, video, and image distributions with thousands of dimensions, we
introduce Accelerated Diffusion Cardest (ADC), the first joint distribution
cardinality estimator based on a downsized diffusion model.
  To calculate the pointwise density value of data distributions, ADC's density
estimator uses a formula that evaluates log-likelihood by integrating the score
function, a gradient mapping which ADC has learned to efficiently approximate
using its lightweight score estimator. To answer ranged queries, ADC's
selectivity estimator first predicts their selectivity using a Gaussian Mixture
Model (GMM), then uses importance sampling Monte Carlo to correct its
predictions with more accurate pointwise density values calculated by the
density estimator. ADC+ further trains a decision tree to identify the
high-volume, high-selectivity queries that the GMM alone can predict very
accurately, in which case it skips the correction phase to prevent Monte Carlo
from adding more variance. Doing so lowers median Q-error and cuts per-query
latency by 25 percent, making ADC+ usually twice as fast as Naru, arguably the
state-of-the-art joint distribution cardinality estimator.
  Numerical experiments using well-established benchmarks show that on all
real-world datasets tested, ADC+ is capable of rivaling Naru and outperforming
MSCN, DeepDB, LW-Tree, and LW-NN using around 66 percent their storage space,
being at least 3 times as accurate as MSCN on 95th and 99th percentile error.
Furthermore, on a synthetic dataset where attributes exhibit complex,
multilateral correlations, ADC and ADC+ are considerably robust while almost
every other learned model suffered significant accuracy declines. In this case,
ADC+ performs better than any other tested model, being 10 times as accurate as
Naru on 95th and 99th percentile error.

- **A Full Stack Framework for High Performance Quantum-Classical Computing**
  - 发表日期：2025-10-23 | 推荐度：0.840 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20128v1
  - 摘要：To address the growing needs for scalable High Performance Computing (HPC)
and Quantum Computing (QC) integration, we present our HPC-QC full stack
framework and its hybrid workload development capability with modular
hardware/device-agnostic software integration approach. The latest development
in extensible interfaces for quantum programming, dispatching, and compilation
within existing mature HPC programming environment are demonstrated. Our HPC-QC
full stack enables high-level, portable invocation of quantum kernels from
commercial quantum SDKs within HPC meta-program in compiled languages (C/C++
and Fortran) as well as Python through a quantum programming interface library
extension. An adaptive circuit knitting hypervisor is being developed to
partition large quantum circuits into sub-circuits that fit on smaller noisy
quantum devices and classical simulators. At the lower-level, we leverage Cray
LLVM-based compilation framework to transform and consume LLVM IR and Quantum
IR (QIR) from commercial quantum software frontends in a retargetable fashion
to different hardware architectures. Several hybrid HPC-QC multi-node multi-CPU
and GPU workloads (including solving linear system of equations, quantum
optimization, and simulating quantum phase transitions) have been demonstrated
on HPE EX supercomputers to illustrate functionality and execution viability
for all three components developed so far. This work provides the framework for
a unified quantum-classical programming environment built upon classical HPC
software stack (compilers, libraries, parallel runtime and process scheduling).

- **Mixing Importance with Diversity: Joint Optimization for KV Cache
  Compression in Large Vision-Language Models**
  - 发表日期：2025-10-23 | 推荐度：0.839 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20707v1
  - 摘要：Recent large vision-language models (LVLMs) demonstrate remarkable
capabilities in processing extended multi-modal sequences, yet the resulting
key-value (KV) cache expansion creates a critical memory bottleneck that
fundamentally limits deployment scalability. While existing KV cache
compression methods focus on retaining high-importance KV pairs to minimize
storage, they often overlook the modality-specific semantic redundancy patterns
that emerge distinctively in multi-modal KV caches. In this work, we first
analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying
levels of redundancy across attention heads. We show that relying solely on
importance can only cover a subset of the full KV cache information
distribution, leading to potential loss of semantic coverage. To address this,
we propose \texttt{MixKV}, a novel method that mixes importance with diversity
for optimized KV cache compression in LVLMs. \texttt{MixKV} adapts to head-wise
semantic redundancy, selectively balancing diversity and importance when
compressing KV pairs. Extensive experiments demonstrate that \texttt{MixKV}
consistently enhances existing methods across multiple LVLMs. Under extreme
compression (budget=64), \texttt{MixKV} improves baseline methods by an average
of \textbf{5.1\%} across five multi-modal understanding benchmarks and achieves
remarkable gains of \textbf{8.0\%} and \textbf{9.0\%} for SnapKV and AdaKV on
GUI grounding tasks, all while maintaining comparable inference efficiency.
Furthermore, \texttt{MixKV} extends seamlessly to LLMs with comparable
performance gains. Our code is available at
\href{https://github.com/xuyang-liu16/MixKV}{\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.

- **Multi-layer Optimized Coordination of Smart Building Resources in Active
  Power Distribution Systems**
  - 发表日期：2025-10-23 | 推荐度：0.837 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20313v1
  - 摘要：This paper proposes a multi-actor coordination platform for the optimal
utilization of smart buildings resources, including roof top PV generation and
battery energy storage system (BESS), in active power distribution systems. The
proposed multi-actor coordination includes the Smart Building Coordinator
(SBC), Micro-Grid Coordinator (MGC) and Distribution System Coordinator (DSC).
The coordinators operate independently and only exchange limited information
with each other to reach an optimal solution. In the proposed platform, a
hierarchical optimization problem is solved to optimally determine the
operating point of all distribution system resources. The proposed platform
fully preserves the confidentiality of the behind the meter (BTM) data of the
buildings since no information about the status of the PV system, BESS, and
load of the building is shared with the owner of the power system. The proposed
platform has a flexible and scalable architecture where the computational task
of coordinating microgrids and smart buildings with distribution grid is
performed locally at the MGC and SBC layers, respectively. Numerical
simulations show the efficacy of the proposed platform in coordinating the BTM
resources with the rest of the distribution system.

- **High Gain Fusion Target Design using Generative Artificial Intelligence**
  - 发表日期：2025-10-23 | 推荐度：0.836 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20105v1
  - 摘要：By returning to the topological basics of fusion target design, Generative
Artificial Intelligence (genAI) is used to specify how to initially configure
and drive the optimally entangled topological state, and stabilize that
topological state from disruption. This can be applied to all methods;
including tokamaks, laser-driven schemes, and pulsed-power driven schemes. The
result is practical, room temperature targets that can yield up to 10 GJ of
energy, driven by as little as 3 MJ of absorbed energy. The genAI is based on
the concept of Ubuntu that replaces the Deep Convolutional Neural Network
approximation of a functional, with the formula for the generating functional
of a canonical transformation from the domain of the canonical field momentums
and fields, to the domain of the canonical momentums and coordinates, that is
the Reduced Order Model. This formula is a logical process of renormalization,
enabling Heisenberg's canonical approach to field theory, via calculation of
the S-matrix, given observation of the fields. This can be viewed as
topological characterization and control of collective, that is complex,
systems.

- **Dependency-Aware Task Offloading in Multi-UAV Assisted Collaborative
  Mobile Edge Computing**
  - 发表日期：2025-10-23 | 推荐度：0.835 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20149v1
  - 摘要：This paper proposes a novel multi-unmanned aerial vehicle (UAV) assisted
collaborative mobile edge computing (MEC) framework, where the computing tasks
of terminal devices (TDs) can be decomposed into serial or parallel sub-tasks
and offloaded to collaborative UAVs. We first model the dependencies among all
sub-tasks as a directed acyclic graph (DAG) and design a two-timescale frame
structure to decouple the sub-task interdependencies for sub-task scheduling.
Then, a joint sub-task offloading, computational resource allocation, and UAV
trajectories optimization problem is formulated, which aims to minimize the
system cost, i.e., the weighted sum of the task completion delay and the system
energy consumption. To solve this non-convex mixed-integer nonlinear
programming (MINLP) problem, a penalty dual decomposition and successive convex
approximation (PDD-SCA) algorithm is developed. Particularly, the original
MINLP problem is equivalently transferred into a continuous form relying on PDD
theory. By decoupling the resulting problem into three nested subproblems, the
SCA method is further combined to recast the non-convex components and obtain
desirable solutions. Numerical results demonstrate that: 1) Compared to the
benchmark algorithms, the proposed scheme can significantly reduce the system
cost, and thus realize an improved trade-off between task latency and energy
consumption; 2) The proposed algorithm can achieve an efficient workload
balancing for distributed computation across multiple UAVs.

- **Leveraging the Power of Large Language Models in Entity Linking via
  Adaptive Routing and Targeted Reasoning**
  - 发表日期：2025-10-23 | 推荐度：0.835 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20098v1
  - 摘要：Entity Linking (EL) has traditionally relied on large annotated datasets and
extensive model fine-tuning. While recent few-shot methods leverage large
language models (LLMs) through prompting to reduce training requirements, they
often suffer from inefficiencies due to expensive LLM-based reasoning. ARTER
(Adaptive Routing and Targeted Entity Reasoning) presents a structured pipeline
that achieves high performance without deep fine-tuning by strategically
combining candidate generation, context-based scoring, adaptive routing, and
selective reasoning. ARTER computes a small set of complementary signals(both
embedding and LLM-based) over the retrieved candidates to categorize contextual
mentions into easy and hard cases. The cases are then handled by a
low-computational entity linker (e.g. ReFinED) and more expensive targeted
LLM-based reasoning respectively. On standard benchmarks, ARTER outperforms
ReFinED by up to +4.47%, with an average gain of +2.53% on 5 out of 6 datasets,
and performs comparably to pipelines using LLM-based reasoning for all
mentions, while being as twice as efficient in terms of the number of LLM
tokens.

- **ComProScanner: A multi-agent based framework for composition-property
  structured data extraction from scientific literature**
  - 发表日期：2025-10-23 | 推荐度：0.833 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20362v1
  - 摘要：Since the advent of various pre-trained large language models, extracting
structured knowledge from scientific text has experienced a revolutionary
change compared with traditional machine learning or natural language
processing techniques. Despite these advances, accessible automated tools that
allow users to construct, validate, and visualise datasets from scientific
literature extraction remain scarce. We therefore developed ComProScanner, an
autonomous multi-agent platform that facilitates the extraction, validation,
classification, and visualisation of machine-readable chemical compositions and
properties, integrated with synthesis data from journal articles for
comprehensive database creation. We evaluated our framework using 100 journal
articles against 10 different LLMs, including both open-source and proprietary
models, to extract highly complex compositions associated with ceramic
piezoelectric materials and corresponding piezoelectric strain coefficients
(d33), motivated by the lack of a large dataset for such materials.
DeepSeek-V3-0324 outperformed all models with a significant overall accuracy of
0.82. This framework provides a simple, user-friendly, readily-usable package
for extracting highly complex experimental data buried in the literature to
build machine learning or deep learning datasets.

- **A computational model and tool for generating more novel opportunities
  in professional innovation processes**
  - 发表日期：2025-10-23 | 推荐度：0.833 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20402v1
  - 摘要：This paper presents a new computational model of creative outcomes, informed
by creativity theories and techniques, which was implemented to generate more
novel opportunities for innovation projects. The model implemented five
functions that were developed to contribute to the generation of innovation
opportunities with higher novelty without loss of usefulness. The model was
evaluated using opportunities generated for an innovation project in the
hospitality sector. The evaluation revealed that the computational model
generated outcomes that were more novel and/or useful than outcomes from
Notebook LM and ChatGPT4o. However, not all model functions contributed to the
generation of more novel opportunities, leading to new directions for further
model development

- **Deep Learning in Dental Image Analysis: A Systematic Review of Datasets,
  Methodologies, and Emerging Challenges**
  - 发表日期：2025-10-23 | 推荐度：0.833 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20634v1
  - 摘要：Efficient analysis and processing of dental images are crucial for dentists
to achieve accurate diagnosis and optimal treatment planning. However, dental
imaging inherently poses several challenges, such as low contrast, metallic
artifacts, and variations in projection angles. Combined with the subjectivity
arising from differences in clinicians' expertise, manual interpretation often
proves time-consuming and prone to inconsistency. Artificial intelligence
(AI)-based automated dental image analysis (DIA) offers a promising solution to
these issues and has become an integral part of computer-aided dental diagnosis
and treatment. Among various AI technologies, deep learning (DL) stands out as
the most widely applied and influential approach due to its superior feature
extraction and representation capabilities. To comprehensively summarize recent
progress in this field, we focus on the two fundamental aspects of DL
research-datasets and models. In this paper, we systematically review 260
studies on DL applications in DIA, including 49 papers on publicly available
dental datasets and 211 papers on DL-based algorithms. We first introduce the
basic concepts of dental imaging and summarize the characteristics and
acquisition methods of existing datasets. Then, we present the foundational
techniques of DL and categorize relevant models and algorithms according to
different DIA tasks, analyzing their network architectures, optimization
strategies, training methods, and performance. Furthermore, we summarize
commonly used training and evaluation metrics in the DIA domain. Finally, we
discuss the current challenges of existing research and outline potential
future directions. We hope that this work provides a valuable and systematic
reference for researchers in this field. All supplementary materials and
detailed comparison tables will be made publicly available on GitHub.

- **ALICE-LRI: A General Method for Lossless Range Image Generation for
  Spinning LiDAR Sensors without Calibration Metadata**
  - 发表日期：2025-10-23 | 推荐度：0.833 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20708v1
  - 摘要：3D LiDAR sensors are essential for autonomous navigation, environmental
monitoring, and precision mapping in remote sensing applications. To
efficiently process the massive point clouds generated by these sensors, LiDAR
data is often projected into 2D range images that organize points by their
angular positions and distances. While these range image representations enable
efficient processing, conventional projection methods suffer from fundamental
geometric inconsistencies that cause irreversible information loss,
compromising high-fidelity applications. We present ALICE-LRI (Automatic LiDAR
Intrinsic Calibration Estimation for Lossless Range Images), the first general,
sensor-agnostic method that achieves lossless range image generation from
spinning LiDAR point clouds without requiring manufacturer metadata or
calibration files. Our algorithm automatically reverse-engineers the intrinsic
geometry of any spinning LiDAR sensor by inferring critical parameters
including laser beam configuration, angular distributions, and per-beam
calibration corrections, enabling lossless projection and complete point cloud
reconstruction with zero point loss. Comprehensive evaluation across the
complete KITTI and DurLAR datasets demonstrates that ALICE-LRI achieves perfect
point preservation, with zero points lost across all point clouds. Geometric
accuracy is maintained well within sensor precision limits, establishing
geometric losslessness with real-time performance. We also present a
compression case study that validates substantial downstream benefits,
demonstrating significant quality improvements in practical applications. This
paradigm shift from approximate to lossless LiDAR projections opens new
possibilities for high-precision remote sensing applications requiring complete
geometric preservation.

- **Performance of an open-source image-based history matching framework for
  CO$_2$ storage**
  - 发表日期：2025-10-23 | 推荐度：0.832 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20614v1
  - 摘要：We present a history matching (HM) workflow applied to the International
FluidFlower benchmark study dataset, which features high-resolution images of
CO$_2$ storage in a meter-scale, geologically complex reservoir. The dataset
provides dense spatial and temporal observations of fluid displacement,
offering a rare opportunity to validate and enhance HM techniques for
geological carbon storage (GCS). The combination of detailed experimental data
and direct visual observation of flow behavior at this scale is novel and
valuable. This study explores the potential and limitations of using
experimental data to calibrate standard models for GCS simulation. By
leveraging high-resolution images and resulting interpretations of fluid phase
distributions, we adjust uncertain parameters and reduce the mismatch between
simulation results and observed data. Simulations are performed using the
open-source OPM Flow simulator, while the open-source Everest decision-making
tool is employed to conduct the HM. After the HM process, the final simulation
results show good agreement with the experimental CO$_2$ storage data. This
suggests that the system can be effectively described using standard flow
equations, conventional saturation functions, and typical PVT properties for
CO$_2$-brine mixtures. Our results demonstrate that the Wasserstein distance is
a particularly effective metric for matching multi-phase, multi-component flow
data. The entire workflow is implemented in a Python package named pofff
(Python OPM Flow FluidFlower), which organizes all functionality through a
single input file. This design ensures reproducibility and facilitates future
extensions of the study.

- **Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization
  Leveraging LiDAR-Based Robot Detections**
  - 发表日期：2025-10-23 | 推荐度：0.831 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20480v1
  - 摘要：Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

- **Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous
  Parking**
  - 发表日期：2025-10-23 | 推荐度：0.831 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20335v1
  - 摘要：Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

- **AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for
  Scalable LLM Training**
  - 发表日期：2025-10-23 | 推荐度：0.831 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20111v1
  - 摘要：The training efficiency and scalability of language models on massive
clusters currently remain a critical bottleneck. Mainstream approaches like ND
parallelism are often cumbersome and complex, while flexible alternatives such
as the Zero Redundancy Optimizer (ZeRO) are frequently hampered by
communication overhead. In this paper, we propose Asynchronous Hierarchical
Zero Parallelism (AsyncHZP), a novel asynchronous variant of ZeRO designed to
achieve superior performance while maintaining simplicity and memory
efficiency. Unlike traditional ZeRO, which employs over-fine-grained sharding
that can lead to inefficient communication, AsyncHZP adaptively reshards
parameters, gradients, and optimizer states across different replica groups.
This strategy optimizes device memory utilization and significantly reduces
communication overhead. In addition, we also design a multi-stream asynchronous
scheduling method that executes parameter all-gather and gradient
reduce-scatter operations in dedicated background threads, effectively
overlapping communication with computation while incurring negligible memory
fragmentation. Empirical evaluations on both Dense and Mixture-of-Experts (MoE)
models confirm that AsyncHZP maintains robust stability at scale. It
consistently outperforms classic ND parallelism, achieving state-of-the-art
performance without complex strategic tuning, thereby simplifying the path to
efficient large-scale training.

- **Decoding-Free Sampling Strategies for LLM Marginalization**
  - 发表日期：2025-10-23 | 推荐度：0.831 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20208v1
  - 摘要：Modern language models operate on subword-tokenized text in order to make a
trade-off between model size, inference speed, and vocabulary coverage. A side
effect of this is that, during inference, models are evaluated by measuring the
probability of only the specific tokenization produced as the output, despite
there being many possible ways to represent the same text with a subword
vocabulary. Recent studies have argued instead for evaluating LLMs by
marginalization - the probability mass of all tokenizations of a given text.
  Marginalization is difficult due to the number of possible tokenizations of a
text, so often approximate marginalization is done via sampling. However, a
downside of sampling is that an expensive generation step must be performed by
the LLM for each sample, which limits the number of samples that can be
acquired given a runtime budget, and therefore also the accuracy of the
approximation. Since computing the probability of a sequence given the
tokenization is relatively cheap compared to actually generating it, we
investigate sampling strategies that are decoding-free - they require no
generation from the LLM, instead relying entirely on extremely cheap sampling
strategies that are model and tokenizer agnostic.
  We investigate the approximation quality and speed of decoding-free sampling
strategies for a number of open models to find that they provide sufficiently
accurate marginal estimates at a small fraction of the runtime cost and
demonstrate its use on a set of downstream inference tasks.

- **Learning Optimal Power Flow with Pointwise Constraints**
  - 发表日期：2025-10-23 | 推荐度：0.830 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20777v1
  - 摘要：Training learning parameterizations to solve optimal power flow (OPF) with
pointwise constraints is proposed. In this novel training approach, a learning
parameterization is substituted directly into an OPF problem with constraints
required to hold over all problem instances. This is different from existing
supervised learning methods in which constraints are required to hold across
the average of problem instances. Training with pointwise constraints is
undertaken in the dual domain with the use of augmented Lagrangian and dual
gradient ascent algorithm. Numerical experiments demonstrate that training with
pointwise constraints produces solutions with smaller constraint violations.
Experiments further demonstrated that pointwise constraints are most effective
at reducing constraint violations in corner cases - defined as those
realizations in which constraints are most difficult to satisfy. Gains are most
pronounced in power systems with large numbers of buses.

- **Empower Words: DualGround for Structured Phrase and Sentence-Level
  Temporal Grounding**
  - 发表日期：2025-10-23 | 推荐度：0.830 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20244v1
  - 摘要：Video Temporal Grounding (VTG) aims to localize temporal segments in long,
untrimmed videos that align with a given natural language query. This task
typically comprises two subtasks: Moment Retrieval (MR) and Highlight Detection
(HD). While recent advances have been progressed by powerful pretrained
vision-language models such as CLIP and InternVideo2, existing approaches
commonly treat all text tokens uniformly during crossmodal attention,
disregarding their distinct semantic roles. To validate the limitations of this
approach, we conduct controlled experiments demonstrating that VTG models
overly rely on [EOS]-driven global semantics while failing to effectively
utilize word-level signals, which limits their ability to achieve fine-grained
temporal alignment. Motivated by this limitation, we propose DualGround, a
dual-branch architecture that explicitly separates global and local semantics
by routing the [EOS] token through a sentence-level path and clustering word
tokens into phrase-level units for localized grounding. Our method introduces
(1) tokenrole- aware cross modal interaction strategies that align video
features with sentence-level and phrase-level semantics in a structurally
disentangled manner, and (2) a joint modeling framework that not only improves
global sentence-level alignment but also enhances finegrained temporal
grounding by leveraging structured phrase-aware context. This design allows the
model to capture both coarse and localized semantics, enabling more expressive
and context-aware video grounding. DualGround achieves state-of-the-art
performance on both Moment Retrieval and Highlight Detection tasks across
QVHighlights and Charades- STA benchmarks, demonstrating the effectiveness of
disentangled semantic modeling in video-language alignment.

- **Convexity of Neural Codes with Four Maximal Codewords**
  - 发表日期：2025-10-23 | 推荐度：0.828 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20323v1
  - 摘要：Place cells are neurons that act as biological position sensors, associated
with and firing in response to regions of an environment to situate an organism
in space. These associations are recorded in (combinatorial) neural codes,
motivating the following mathematical question: Which neural codes are
generated by a collection of convex open sets in Euclidean space? Giusti and
Itskov showed that a necessary condition for convexity is the absence of
``local obstructions." This necessary condition is, in fact, sufficient for
certain families of codes. One such family consists of all codes with up to
three maximal codewords. In this article, we investigate codes with four
maximal codewords, showing that for many such codes, convexity is characterized
by the absence of local obstructions, whereas for other such codes, convexity
is characterized by the absence of local obstructions and a second type of
obstruction, a ``wheel". Key to our analysis is a case-by-case investigation
based on the nerve complex of the set of maximal codewords of a neural code. Up
to symmetry, there are 20 possible nerves; and our results fully characterize
convexity in 15 of the 20 cases.

- **EmbodiedBrain: Expanding Performance Boundaries of Task Planning for
  Embodied Intelligence**
  - 发表日期：2025-10-23 | 推荐度：0.828 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20578v1
  - 摘要：The realization of Artificial General Intelligence (AGI) necessitates
Embodied AI agents capable of robust spatial perception, effective task
planning, and adaptive execution in physical environments. However, current
large language models (LLMs) and multimodal LLMs (MLLMs) for embodied tasks
suffer from key limitations, including a significant gap between model design
and agent requirements, an unavoidable trade-off between real-time latency and
performance, and the use of unauthentic, offline evaluation metrics. To address
these challenges, we propose EmbodiedBrain, a novel vision-language foundation
model available in both 7B and 32B parameter sizes. Our framework features an
agent-aligned data structure and employs a powerful training methodology that
integrates large-scale Supervised Fine-Tuning (SFT) with Step-Augumented Group
Relative Policy Optimization (Step-GRPO), which boosts long-horizon task
success by integrating preceding steps as Guided Precursors. Furthermore, we
incorporate a comprehensive reward system, including a Generative Reward Model
(GRM) accelerated at the infrastructure level, to improve training efficiency.
For enable thorough validation, we establish a three-part evaluation system
encompassing General, Planning, and End-to-End Simulation Benchmarks,
highlighted by the proposal and open-sourcing of a novel, challenging
simulation environment. Experimental results demonstrate that EmbodiedBrain
achieves superior performance across all metrics, establishing a new
state-of-the-art for embodied foundation models. Towards paving the way for the
next generation of generalist embodied agents, we open-source all of our data,
model weight, and evaluating methods, which are available at
https://zterobot.github.io/EmbodiedBrain.github.io.

- **Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role
  of Context**
  - 发表日期：2025-10-23 | 推荐度：0.827 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20229v1
  - 摘要：Large Vision-Language Models (LVLMs) have made significant progress in recent
years but are also prone to hallucination issues. They exhibit more
hallucinations in longer, free-form responses, often attributed to accumulated
uncertainties. In this paper, we ask: Does increased hallucination result
solely from length-induced errors, or is there a deeper underlying mechanism?
After a series of preliminary experiments and findings, we suggest that the
risk of hallucinations is not caused by length itself but by the increased
reliance on context for coherence and completeness in longer responses.
Building on these insights, we propose a novel "induce-detect-suppress"
framework that actively induces hallucinations through deliberately designed
contexts, leverages induced instances for early detection of high-risk cases,
and ultimately suppresses potential object-level hallucinations during actual
decoding. Our approach achieves consistent, significant improvements across all
benchmarks, demonstrating its efficacy. The strong detection and improved
hallucination mitigation not only validate our framework but, more importantly,
re-validate our hypothesis on context. Rather than solely pursuing performance
gains, this study aims to provide new insights and serves as a first step
toward a deeper exploration of hallucinations in LVLMs' longer responses.

- **LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning
  Framework for Recommender Systems**
  - 发表日期：2025-10-23 | 推荐度：0.827 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20327v1
  - 摘要：With the growing demand for safeguarding sensitive user information in
recommender systems, recommendation attribute unlearning is receiving
increasing attention. Existing studies predominantly focus on single-attribute
unlearning. However, privacy protection requirements in the real world often
involve multiple sensitive attributes and are dynamic. Existing
single-attribute unlearning methods cannot meet these real-world requirements
due to i) CH1: the inability to handle multiple unlearning requests
simultaneously, and ii) CH2: the lack of efficient adaptability to dynamic
unlearning needs. To address these challenges, we propose LEGO, a lightweight
and efficient multiple-attribute unlearning framework. Specifically, we divide
the multiple-attribute unlearning process into two steps: i) Embedding
Calibration removes information related to a specific attribute from user
embedding, and ii) Flexible Combination combines these embeddings into a single
embedding, protecting all sensitive attributes. We frame the unlearning process
as a mutual information minimization problem, providing LEGO a theoretical
guarantee of simultaneous unlearning, thereby addressing CH1. With the two-step
framework, where Embedding Calibration can be performed in parallel and
Flexible Combination is flexible and efficient, we address CH2. Extensive
experiments on three real-world datasets across three representative
recommendation models demonstrate the effectiveness and efficiency of our
proposed framework. Our code and appendix are available at
https://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.

- **On pattern classification with weighted dimensions**
  - 发表日期：2025-10-23 | 推荐度：0.827 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20107v1
  - 摘要：Studies on various facets of pattern classification is often imperative while
working with multi-dimensional samples pertaining to diverse application
scenarios. In this notion, weighted dimension-based distance measure has been
one of the vital considerations in pattern analysis as it reflects the degree
of similarity between samples. Though it is often presumed to be settled with
the pervasive use of Euclidean distance, plethora of issues often surface. In
this paper, we present (a) a detail analysis on the impact of distance measure
norms and weights of dimensions along with visualization, (b) a novel weighting
scheme for each dimension, (c) incorporation of this dimensional weighting
schema into a KNN classifier, and (d) pattern classification on a variety of
synthetic as well as realistic datasets with the developed model. It has
performed well across diverse experiments in comparison to the traditional KNN
under the same experimental setups. Specifically, for gene expression datasets,
it yields significant and consistent gain in classification accuracy (around
10%) in all cross-validation experiments with different values of k. As such
datasets contain limited number of samples of high dimensions, meaningful
selection of nearest neighbours is desirable, and this requirement is
reasonably met by regulating the shape and size of the region enclosing the k
number of reference samples with the developed weighting schema and appropriate
norm. It, therefore, stands as an important generalization of KNN classifier
powered by weighted Minkowski distance with the present weighting schema.

- **Optimal constant-cost implementations of Clifford operations using
  global interactions**
  - 发表日期：2025-10-23 | 推荐度：0.826 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20730v1
  - 摘要：We investigate quantum circuits built from arbitrary single-qubit operations
combined with programmable all-to-all multiqubit entangling gates that are
native to, among other systems, trapped-ion quantum computing platforms. We
report a constant-cost of no more than four applications of such Clifford
entangling multiqubit gates to realize any sequence of Clifford operations of
any length, without ancillae, which is the theoretically optimal gate count
cost. We do this by implementing any sequence of CNOT gates of any length with
four applications of such gates, without ancillae, and show that the extension
to general Clifford operations incurs no additional cost. We investigate the
required qubit drive power that is associated with our implementation and show
that it is lower than that of a standard approach. Our work introduces a
practical and computationally efficient algorithm to realize these
compilations.

- **New Second-Order Achievability Bounds for Coding with Side Information
  via Type Deviation Convergence**
  - 发表日期：2025-10-23 | 推荐度：0.826 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20241v1
  - 摘要：We propose a framework for second-order achievability, called type deviation
convergence, that is generally applicable to settings in network information
theory, and is especially suitable for lossy source coding and channel coding
with cost. We give a second-order achievability bound for lossy source coding
with side information at the decoder (Wyner-Ziv problem) that improves upon all
known bounds (e.g., Watanabe-Kuzuoka-Tan, Yassaee-Aref-Gohari and
Li-Anantharam). We also give second-order achievability bounds for lossy
compression where side information may be absent (Heegard-Berger problem) and
channels with noncausal state information at the encoder and cost constraint
(Gelfand-Pinsker problem with cost) that improve upon previous bounds.

- **Analyticup E-commerce Product Search Competition Technical Report from
  Team Tredence_AICOE**
  - 发表日期：2025-10-23 | 推荐度：0.826 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20674v1
  - 摘要：This study presents the multilingual e-commerce search system developed by
the Tredence_AICOE team. The competition features two multilingual relevance
tasks: Query-Category (QC) Relevance, which evaluates how well a user's search
query aligns with a product category, and Query-Item (QI) Relevance, which
measures the match between a multilingual search query and an individual
product listing. To ensure full language coverage, we performed data
augmentation by translating existing datasets into languages missing from the
development set, enabling training across all target languages. We fine-tuned
Gemma-3 12B and Qwen-2.5 14B model for both tasks using multiple strategies.
The Gemma-3 12B (4-bit) model achieved the best QC performance using original
and translated data, and the best QI performance using original, translated,
and minority class data creation. These approaches secured 4th place on the
final leaderboard, with an average F1-score of 0.8857 on the private test set.

- **Resource-Aware Hybrid Quantum Programming with General Recursion and
  Quantum Control**
  - 发表日期：2025-10-23 | 推荐度：0.825 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20452v1
  - 摘要：This paper introduces the hybrid quantum language with general recursion
$\mathtt{Hyrql}$, driven towards resource-analysis. By design, $\mathtt{Hyrql}$
does not require the specification of an initial set of quantum gates and,
hence, is well amenable towards a generic cost analysis. Indeed, languages
using different sets of quantum gates lead to representations of quantum
circuits whose complexity varies. Towards resource-analysis, a
semantics-preserving compilation algorithm to simply-typed term rewrite systems
is described; allowing a generic reuse of all known techniques for analyzing
the complexity of term rewrite systems. We prove the versatility of this
approach through many examples.

- **Real Deep Research for AI, Robotics and Beyond**
  - 发表日期：2025-10-23 | 推荐度：0.825 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20809v1
  - 摘要：With the rapid growth of research in AI and robotics now producing over
10,000 papers annually it has become increasingly difficult for researchers to
stay up to date. Fast evolving trends, the rise of interdisciplinary work, and
the need to explore domains beyond one's expertise all contribute to this
challenge. To address these issues, we propose a generalizable pipeline capable
of systematically analyzing any research area: identifying emerging trends,
uncovering cross domain opportunities, and offering concrete starting points
for new inquiry. In this work, we present Real Deep Research (RDR) a
comprehensive framework applied to the domains of AI and robotics, with a
particular focus on foundation models and robotics advancements. We also
briefly extend our analysis to other areas of science. The main paper details
the construction of the RDR pipeline, while the appendix provides extensive
results across each analyzed topic. We hope this work sheds light for
researchers working in the field of AI and beyond.

- **NeuPerm: Disrupting Malware Hidden in Neural Network Parameters by
  Leveraging Permutation Symmetry**
  - 发表日期：2025-10-23 | 推荐度：0.825 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20367v1
  - 摘要：Pretrained deep learning model sharing holds tremendous value for researchers
and enterprises alike. It allows them to apply deep learning by fine-tuning
models at a fraction of the cost of training a brand-new model. However, model
sharing exposes end-users to cyber threats that leverage the models for
malicious purposes. Attackers can use model sharing by hiding self-executing
malware inside neural network parameters and then distributing them for
unsuspecting users to unknowingly directly execute them, or indirectly as a
dependency in another software. In this work, we propose NeuPerm, a simple yet
effec- tive way of disrupting such malware by leveraging the theoretical
property of neural network permutation symmetry. Our method has little to no
effect on model performance at all, and we empirically show it successfully
disrupts state-of-the-art attacks that were only previously addressed using
quantization, a highly complex process. NeuPerm is shown to work on LLMs, a
feat that no other previous similar works have achieved. The source code is
available at https://github.com/danigil/NeuPerm.git.

- **NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew**
  - 发表日期：2025-10-23 | 推荐度：0.825 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20386v1
  - 摘要：Since their initial release, BERT models have demonstrated exceptional
performance on a variety of tasks, despite their relatively small size
(BERT-base has ~100M parameters). Nevertheless, the architectural choices used
in these models are outdated compared to newer transformer-based models such as
Llama3 and Qwen3. In recent months, several architectures have been proposed to
close this gap. ModernBERT and NeoBERT both show strong improvements on English
benchmarks and significantly extend the supported context window. Following
their successes, we introduce NeoDictaBERT and NeoDictaBERT-bilingual:
BERT-style models trained using the same architecture as NeoBERT, with a
dedicated focus on Hebrew texts. These models outperform existing ones on
almost all Hebrew benchmarks and provide a strong foundation for downstream
tasks. Notably, the NeoDictaBERT-bilingual model shows strong results on
retrieval tasks, outperforming other multilingual models of similar size. In
this paper, we describe the training process and report results across various
benchmarks. We release the models to the community as part of our goal to
advance research and development in Hebrew NLP.

- **PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast
  Cancer Detection**
  - 发表日期：2025-10-23 | 推荐度：0.824 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20611v1
  - 摘要：Breast cancer is considered the most critical and frequently diagnosed cancer
in women worldwide, leading to an increase in cancer-related mortality. Early
and accurate detection is crucial as it can help mitigate possible threats
while improving survival rates. In terms of prediction, conventional diagnostic
methods are often limited by variability, cost, and, most importantly, risk of
misdiagnosis. To address these challenges, machine learning (ML) has emerged as
a powerful tool for computer-aided diagnosis, with feature selection playing a
vital role in improving model performance and interpretability. This research
study proposes an integrated framework that incorporates customized Particle
Swarm Optimization (PSO) for feature selection. This framework has been
evaluated on a comprehensive set of 29 different models, spanning classical
classifiers, ensemble techniques, neural networks, probabilistic algorithms,
and instance-based algorithms. To ensure interpretability and clinical
relevance, the study uses cross-validation in conjunction with explainable AI
methods. Experimental evaluation showed that the proposed approach achieved a
superior score of 99.1\% across all performance metrics, including accuracy and
precision, while effectively reducing dimensionality and providing transparent,
model-agnostic explanations. The results highlight the potential of combining
swarm intelligence with explainable ML for robust, trustworthy, and clinically
meaningful breast cancer diagnosis.

- **Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents**
  - 发表日期：2025-10-23 | 推荐度：0.824 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20211v1
  - 摘要：Cloud infrastructure is managed through a mix of interfaces -- traditionally,
cloud consoles, command-line interfaces (CLI), and SDKs are the tools of
choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have
quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the
infrastructure in a "source-of-truth" configuration. They are capable of
automatically carrying out modifications to the cloud -- deploying, updating,
or destroying resources -- to bring the actual infrastructure into alignment
with the IaC configuration. However, when IaC is used alongside consoles, CLIs,
or SDKs, it loses visibility into external changes, causing infrastructure
drift, where the configuration becomes outdated, and later IaC operations may
undo valid updates or trigger errors.
  We present NSync, an automated system for IaC reconciliation that propagates
out-of-band changes back into the IaC program. Our key insight is that
infrastructure changes eventually all occur via cloud API invocations -- the
lowest layer for cloud management operations. NSync gleans insights from API
traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update
the IaC configuration to capture the changes). It employs an agentic
architecture that leverages LLMs to infer high-level intents from noisy API
sequences, synthesize targeted IaC updates using specialized tools, and
continually improve through a self-evolving knowledge base of past
reconciliations. We further introduce a novel evaluation pipeline for injecting
realistic drifts into cloud infrastructure and assessing reconciliation
performance. Experiments across five real-world Terraform projects and 372
drift scenarios show that NSync outperforms the baseline both in terms of
accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\times$
improvement).

- **Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models**
  - 发表日期：2025-10-23 | 推荐度：0.824 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20198v1
  - 摘要：This paper explores the spatial reasoning capability of large language models
(LLMs) over textual input through a suite of five tasks aimed at probing their
spatial understanding and computational abilities. The models were tested on
both fundamental spatial reasoning and multi-step problem-solving within
structured grid-based environments using tasks such as quadrant identification,
geometric transformations, distance evaluation, word searches, and tile
sliding. Each task was scaled in complexity through increasing grid dimensions,
requiring models to extend beyond simple pattern recognition into abstract
spatial reasoning. Our results reveal that while LLMs demonstrate moderate
success in all tasks with small complexity and size, performance drops off
rapidly as scale increases, with an average loss in accuracy of 42.7%, and
reaching as high as 84%. Every test that began with over 50% accuracy showed a
loss of at least 48%, illustrating the consistent nature of the deterioration.
Furthermore, their struggles with scaling complexity hint at a lack of robust
spatial representations in their underlying architectures. This paper
underscores the gap between linguistic and spatial reasoning in LLMs, offering
insights into their current limitations, and laying the groundwork for future
integrative benchmarks at the intersection of language and geometry.

- **Trust, But Verify: An Empirical Evaluation of AI-Generated Code for SDN
  Controllers**
  - 发表日期：2025-10-23 | 推荐度：0.823 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20703v1
  - 摘要：Generative Artificial Intelligence (AI) tools have been used to generate
human-like content across multiple domains (e.g., sound, image, text, and
programming). However, their reliability in terms of correctness and
functionality in novel contexts such as programmable networks remains unclear.
Hence, this paper presents an empirical evaluation of the source code of a POX
controller generated by different AI tools, namely ChatGPT, Copilot, DeepSeek,
and BlackBox.ai. To evaluate such a code, three networking tasks of increasing
complexity were defined and for each task, zero-shot and few-shot prompting
techniques were input to the tools. Next, the output code was tested in
emulated network topologies with Mininet and analyzed according to
functionality, correctness, and the need for manual fixes. Results show that
all evaluated models can produce functional controllers. However, ChatGPT and
DeepSeek exhibited higher consistency and code quality, while Copilot and
BlackBox.ai required more adjustments.

- **Incomplete U-Statistics of Equireplicate Designs: Berry-Esseen Bound and
  Efficient Construction**
  - 发表日期：2025-10-23 | 推荐度：0.822 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20755v1
  - 摘要：U-statistics are a fundamental class of estimators that generalize the sample
mean and underpin much of nonparametric statistics. Although extensively
studied in both statistics and probability, key challenges remain: their high
computational cost - addressed partly through incomplete U-statistics - and
their non-standard asymptotic behavior in the degenerate case, which typically
requires resampling methods for hypothesis testing. This paper presents a novel
perspective on U-statistics, grounded in hypergraph theory and combinatorial
designs. Our approach bypasses the traditional Hoeffding decomposition, the
main analytical tool in this literature but one highly sensitive to degeneracy.
By characterizing the dependence structure of a U-statistic, we derive a
Berry-Esseen bound that applies to all incomplete U-statistics of deterministic
designs, yielding conditions under which Gaussian limiting distributions can be
established even in the degenerate case and when the order diverges. We also
introduce efficient algorithms to construct incomplete U-statistics of
equireplicate designs, a subclass of deterministic designs that, in certain
cases, achieve minimum variance. Finally, we apply our framework to
kernel-based tests that use Maximum Mean Discrepancy (MMD) and Hilbert-Schmidt
Independence Criterion. In a real data example with CIFAR-10, our
permutation-free MMD test delivers substantial computational gains while
retaining power and type I error control.

- **Approximate Replicability in Learning**
  - 发表日期：2025-10-23 | 推荐度：0.821 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20200v1
  - 摘要：Replicability, introduced by (Impagliazzo et al. STOC '22), is the notion
that algorithms should remain stable under a resampling of their inputs (given
access to shared randomness). While a strong and interesting notion of
stability, the cost of replicability can be prohibitive: there is no replicable
algorithm, for instance, for tasks as simple as threshold learning (Bun et al.
STOC '23). Given such strong impossibility results we ask: under what
approximate notions of replicability is learning possible?
  In this work, we propose three natural relaxations of replicability in the
context of PAC learning: (1) Pointwise: the learner must be consistent on any
fixed input, but not across all inputs simultaneously, (2) Approximate: the
learner must output hypotheses that classify most of the distribution
consistently, (3) Semi: the algorithm is fully replicable, but may additionally
use shared unlabeled samples. In all three cases, for constant replicability
parameters, we obtain sample-optimal agnostic PAC learners: (1) and (2) are
achievable for ``free" using $\Theta(d/\alpha^2)$ samples, while (3) requires
$\Theta(d^2/\alpha^2)$ labeled samples.

- **Amplifying Prominent Representations in Multimodal Learning via
  Variational Dirichlet Process**
  - 发表日期：2025-10-23 | 推荐度：0.820 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20736v1
  - 摘要：Developing effective multimodal fusion approaches has become increasingly
essential in many real-world scenarios, such as health care and finance. The
key challenge is how to preserve the feature expressiveness in each modality
while learning cross-modal interactions. Previous approaches primarily focus on
the cross-modal alignment, while over-emphasis on the alignment of marginal
distributions of modalities may impose excess regularization and obstruct
meaningful representations within each modality. The Dirichlet process (DP)
mixture model is a powerful Bayesian non-parametric method that can amplify the
most prominent features by its richer-gets-richer property, which allocates
increasing weights to them. Inspired by this unique characteristic of DP, we
propose a new DP-driven multimodal learning framework that automatically
achieves an optimal balance between prominent intra-modal representation
learning and cross-modal alignment. Specifically, we assume that each modality
follows a mixture of multivariate Gaussian distributions and further adopt DP
to calculate the mixture weights for all the components. This paradigm allows
DP to dynamically allocate the contributions of features and select the most
prominent ones, leveraging its richer-gets-richer property, thus facilitating
multimodal feature fusion. Extensive experiments on several multimodal datasets
demonstrate the superior performance of our model over other competitors.
Ablation analysis further validates the effectiveness of DP in aligning
modality distributions and its robustness to changes in key hyperparameters.
Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git

- **Co-Designing Quantum Codes with Transversal Diagonal Gates via
  Multi-Agent Systems**
  - 发表日期：2025-10-23 | 推荐度：0.819 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20728v1
  - 摘要：We present a multi-agent, human-in-the-loop workflow that co-designs quantum
codes with prescribed transversal diagonal gates. It builds on the Subset-Sum
Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis
strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL)
equalities via small LPs. The workflow is powered by GPT-5 and implemented
within TeXRA (https://texra.ai)-a multi-agent research assistant platform that
supports an iterative tool-use loop agent and a derivation-then-edit workflow
reasoning agent. We work in a LaTeX-Python environment where agents reason,
edit documents, execute code, and synchronize their work to Git/Overleaf.
Within this workspace, three roles collaborate: a Synthesis Agent formulates
the problem; a Search Agent sweeps/screens candidates and exactifies numerics
into rationals; and an Audit Agent independently checks all KL equalities and
the induced logical action. As a first step we focus on distance $d=2$ with
nondegenerate residues. For code dimension $K\in\{2,3,4\}$ and $n\le6$ qubits,
systematic sweeps yield certificate-backed tables cataloging attainable cyclic
logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$
at $n=6$. From verified instances, Synthesis Agent abstracts recurring
structures into closed-form families and proves they satisfy the KL equalities
for all parameters. It further demonstrates that SSLP accommodates residue
degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal
controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts
diagonal-transversal feasibility as an analytical pipeline executed at scale,
combining systematic enumeration with exact analytical reconstruction. It
yields reproducible code constructions, supports targeted extensions to larger
$K$ and higher distances, and leads toward data-driven classification.

- **Modeling to Generate Alternatives for Robustness of Mixed Integer DC
  Optimal Power Flow**
  - 发表日期：2025-10-23 | 推荐度：0.818 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20089v1
  - 摘要：Transmission system operators face a variety of discrete operational
decisions, such as switching of branches and/or devices. Incorporating these
decisions into optimal power flow (OPF) results in mixed-integer non-linear
programming problems (MINLPs), which can't presently be solved at scale in the
required time. Various linearizations of the OPF exist, most famously the
DC-OPF, which can be leveraged to find integer decisions. However, these
linearizations can yield very poor integer solutions in some edge cases, making
them challenging to incorporate into control rooms. This paper introduces the
use of modeling to generate alternatives (MGA) to find alternative solutions to
the linearized problems, reducing the chance of finding no AC feasible
solutions. We test this approach using 13 networks where the DC linearization
results in infeasible integer decisions, and MGA finds a solution in all cases.
The MGA search criteria selected drastically affects the number and quality of
solutions found, so network specific search functions may be necessary.

- **Lens Model Accuracy in the Expected LSST Lensed AGN Sample**
  - 发表日期：2025-10-23 | 推荐度：0.818 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20778v1
  - 摘要：Strong gravitational lensing of active galactic nuclei (AGN) enables
measurements of cosmological parameters through time-delay cosmography (TDC).
With data from the upcoming LSST survey, we anticipate using a sample of
O(1000) lensed AGN for TDC. To prepare for this dataset and enable this
measurement, we construct and analyze a realistic mock sample of 1300 systems
drawn from the OM10 (Oguri & Marshall 2010) catalog of simulated lenses with
AGN sources at $z<3.1$ in order to test a key aspect of the analysis pipeline,
that of the lens modeling. We realize the lenses as power law elliptical mass
distributions and simulate 5-year LSST i-band coadd images. From every image,
we infer the lens mass model parameters using neural posterior estimation
(NPE). Focusing on the key model parameters, $\theta_E$ (the Einstein Radius)
and $\gamma_{lens}$ (the projected mass density profile slope), with consistent
mass-light ellipticity correlations in test and training data, we recover
$\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and
$\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find
that lens light subtraction prior to modeling is only useful when applied to
data sampled from the training prior. If emulated deconvolution is applied to
the data prior to modeling, precision improves across all parameters by a
factor of 2. Finally, we combine the inferred lens mass models using Bayesian
Hierarchical Inference to recover the global properties of the lens sample with
less than 1% bias.

- **Good Enough is Better: Feasibility vs. Pareto-Optimality in Alloy Design**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20125v1
  - 摘要：In alloy design, the search for candidate materials is often framed as an
optimization problem, with the goal of identifying Pareto-optimal solutions
across multiple objectives. However, Pareto-optimal solutions do not
necessarily satisfy all minimum performance thresholds required for practical
deployment. An alternative approach is to treat alloy design as a constraint
satisfaction problem, in which the goal is to identify any solution that meets
all bare minimum requirements across multiple quantities of interest. These
approaches have yet to be benchmarked against each other in the context of
realistic alloy design problems. In this work, we demonstrate that, in
realistic alloy design campaigns involving multiple objectives and constraints,
the constraint satisfaction framework yields a higher likelihood of finding
viable alloys than optimization-based approaches. Furthermore,
constraint-satisfaction approaches find the first viable alloy solutions
earlier than optimization. Our results suggest that focusing on feasibility
rather than optimality can lead to more actionable outcomes in materials
discovery, particularly in highly constrained applications.

- **A Coherence-Based Measure of AGI**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20784v1
  - 摘要：Recent work by \citet{hendrycks2025agidefinition} formalized
\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of
proficiencies across cognitive domains derived from the Cattell--Horn--Carroll
(CHC) model of human cognition. While elegant, this definition assumes
\textit{compensability} -- that exceptional ability in some domains can offset
failure in others. True general intelligence, however, should reflect
\textit{coherent sufficiency}: balanced competence across all essential
domains. We propose a coherence-aware measure of AGI based on the integral of
generalized means over a continuum of compensability exponents. This
formulation spans arithmetic, geometric, and harmonic regimes, and the
resulting \textit{area under the curve} (AUC) quantifies robustness under
varying compensability assumptions. Unlike the arithmetic mean, which rewards
specialization, the AUC penalizes imbalance and captures inter-domain
dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,
the coherence-adjusted AUC reveals that both systems remain far from general
competence despite high arithmetic scores (e.g., GPT-5 at~24\%). Integrating
the generalized mean thus yields a principled, interpretable, and stricter
foundation for measuring genuine progress toward AGI.

- **Thought Communication in Multiagent Collaboration**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20733v1
  - 摘要：Natural language has long enabled human cooperation, but its lossy,
ambiguous, and indirect nature limits the potential of collective intelligence.
While machines are not subject to these constraints, most LLM-based multi-agent
systems still rely solely on natural language, exchanging tokens or their
embeddings. To go beyond language, we introduce a new paradigm, thought
communication, which enables agents to interact directly mind-to-mind, akin to
telepathy. To uncover these latent thoughts in a principled way, we formalize
the process as a general latent variable model, where agent states are
generated by an unknown function of underlying thoughts. We prove that, in a
nonparametric setting without auxiliary information, both shared and private
latent thoughts between any pair of agents can be identified. Moreover, the
global structure of thought sharing, including which agents share which
thoughts and how these relationships are structured, can also be recovered with
theoretical guarantees. Guided by the established theory, we develop a
framework that extracts latent thoughts from all agents prior to communication
and assigns each agent the relevant thoughts, along with their sharing
patterns. This paradigm naturally extends beyond LLMs to all modalities, as
most observational data arise from hidden generative processes. Experiments on
both synthetic and real-world benchmarks validate the theory and demonstrate
the collaborative advantages of thought communication. We hope this work
illuminates the potential of leveraging the hidden world, as many challenges
remain unsolvable through surface-level observation alone, regardless of
compute or data scale.

- **Convergence Analysis of SGD under Expected Smoothness**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20608v1
  - 摘要：Stochastic gradient descent (SGD) is the workhorse of large-scale learning,
yet classical analyses rely on assumptions that can be either too strong
(bounded variance) or too coarse (uniform noise). The expected smoothness (ES)
condition has emerged as a flexible alternative that ties the second moment of
stochastic gradients to the objective value and the full gradient. This paper
presents a self-contained convergence analysis of SGD under ES. We (i) refine
ES with interpretations and sampling-dependent constants; (ii) derive bounds of
the expectation of squared full gradient norm; and (iii) prove $O(1/K)$ rates
with explicit residual errors for various step-size schedules. All proofs are
given in full detail in the appendix. Our treatment unifies and extends recent
threads (Khaled and Richt\'arik, 2020; Umeda and Iiduka, 2025).

- **Multicast-partitioning in Time-triggered Stream Planning for
  Time-Sensitive Networks**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20440v1
  - 摘要：Multicast allows sending a message to multiple recipients without having to
create and send a separate message for each recipient. This preserves network
bandwidth, which is particularly important in time-sensitive networks. These
networks are commonly used to provide latency-bounded communication for
real-time systems in domains like automotive, avionics, industrial internet of
things, automated shop floors, and smart energy grids. The preserved bandwidth
can be used to admit additional real-time messages with specific quality of
service requirements or to reduce the end-to-end latencies for messages of any
type. However, using multicast communication can complicate traffic planning,
as it requires free queues or available downstream egress ports on all branches
of the multicast tree. In this work, we present a novel multicast partitioning
technique to split multicast trees into smaller multicast or unicast trees.
This allows for a more fine-grained trade-off between bandwidth utilization and
traffic scheduling difficulty. Thus, schedulability in dynamic systems can be
improved, in terms the number of admitted streams and the accumulated network
throughput. We evaluated the multicast partitioning on different network
topologies and with three different scheduling algorithms. With the
partitioning, 5-15\% fewer streams were rejected, while achieving 5-125\% more
network throughput, depending on the scheduling algorithm.

- **Efficient Algorithms for Computing Random Walk Centrality**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：10.1109/TKDE.2025.3621520
  - 链接：http://arxiv.org/abs/2510.20604v1
  - 摘要：Random walk centrality is a fundamental metric in graph mining for
quantifying node importance and influence, defined as the weighted average of
hitting times to a node from all other nodes. Despite its ability to capture
rich graph structural information and its wide range of applications, computing
this measure for large networks remains impractical due to the computational
demands of existing methods. In this paper, we present a novel formulation of
random walk centrality, underpinning two scalable algorithms: one leveraging
approximate Cholesky factorization and sparse inverse estimation, while the
other sampling rooted spanning trees. Both algorithms operate in near-linear
time and provide strong approximation guarantees. Extensive experiments on
large real-world networks, including one with over 10 million nodes,
demonstrate the efficiency and approximation quality of the proposed
algorithms.

- **Rediscovering Recurring Routing Results**
  - 发表日期：2025-10-23 | 推荐度：0.817 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20297v1
  - 摘要：Routing is central to networking performance, including: (1) latency in
anycast services and websites served from multiple locations,(2) networking
expenses and throughput in multi-homed enterprises, (3) the ability to keep
traffic domestic when considering data sovereignty. However, understanding and
managing how routing affects these services is challenging. Operators use
Traffic Engineering (TE) with BGP to optimize network performance, but what
they get is the result of all BGP policies throughout the Internet, not just
their local choices. Our paper proposes Fenrir, a new system to rediscover
recurring routing results. Fenrir can discover changes in network routing, even
when it happens multiple hops away from the observer. Fenrir also provides new
methods to quantify the degree of routing change, and to identify routing
"modes" that may reappear. Second, we show that Fenrir can be applied to many
different problems: we use five instances of three different types of systems
to illustrate the generalization: anycast catchments showing in a root DNS
service, route optimization for two multi-homed enterprises, and website
selection for two of the top-10 web services. Each type requires different
types of active measurements, data cleaning and weighting. We demonstrate
Fenrir's methods of detecting and quantifying change are helpful because they
all face similar operational questions: How much effect did traffic engineering
have? Did a third-party change alter my routing? In either case, is the current
routing new, or is it like a routing mode I saw before?

- **Every Question Has Its Own Value: Reinforcement Learning with Explicit
  Human Values**
  - 发表日期：2025-10-23 | 推荐度：0.816 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20187v1
  - 摘要：We propose Reinforcement Learning with Explicit Human Values (RLEV), a method
that aligns Large Language Model (LLM) optimization directly with quantifiable
human value signals. While Reinforcement Learning with Verifiable Rewards
(RLVR) effectively trains models in objective domains using binary correctness
rewards, it overlooks that not all tasks are equally significant. RLEV extends
this framework by incorporating human-defined value signals directly into the
reward function. Using exam-style data with explicit ground-truth value labels,
RLEV consistently outperforms correctness-only baselines across multiple RL
algorithms and model scales. Crucially, RLEV policies not only improve
value-weighted accuracy but also learn a value-sensitive termination policy:
concise for low-value prompts, thorough for high-value ones. We demonstrate
this behavior stems from value-weighted gradient amplification on
end-of-sequence tokens. Ablation studies confirm the gain is causally linked to
value alignment. RLEV remains robust under noisy value signals, such as
difficulty-based labels, demonstrating that optimizing for an explicit utility
function offers a practical path to aligning LLMs with human priorities.

- **SafeFFI: Efficient Sanitization at the Boundary Between Safe and Unsafe
  Code in Rust and Mixed-Language Applications**
  - 发表日期：2025-10-23 | 推荐度：0.816 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20688v1
  - 摘要：Unsafe Rust code is necessary for interoperability with C/C++ libraries and
implementing low-level data structures, but it can cause memory safety
violations in otherwise memory-safe Rust programs. Sanitizers can catch such
memory errors at runtime, but introduce many unnecessary checks even for memory
accesses guaranteed safe by the Rust type system. We introduce SafeFFI, a
system for optimizing memory safety instrumentation in Rust binaries such that
checks occur at the boundary between unsafe and safe code, handing over the
enforcement of memory safety from the sanitizer to the Rust type system. Unlike
previous approaches, our design avoids expensive whole-program analysis and
adds much less compile-time overhead (2.64x compared to over 8.83x). On a
collection of popular Rust crates and known vulnerable Rust code, SafeFFI
achieves superior performance compared to state-of-the-art systems, reducing
sanitizer checks by up to 98%, while maintaining correctness and flagging all
spatial and temporal memory safety violations.

- **Balanced Popularity in Multi-Product Billboard Advertisement**
  - 发表日期：2025-10-23 | 推荐度：0.815 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20600v1
  - 摘要：The billboard advertisement has emerged as an effective out-of-home
advertisement technique where the objective is to choose a limited number of
slots to play some advertisement content (e.g., animation, video, etc.) with
the hope that the content will be visible to a large number of travelers, and
this will be helpful to earn more revenue. In this paper, we study a variant of
the influential slot selection problem where the advertiser wants to promote
multiple products. Formally, we call this problem the \textsc{Multi-Product
Influence Maximization Problem for the Balanced Popularity} Problem. The input
to our problem is a trajectory and a billboard database, as well as a budget
for each product. The goal here is to choose a subset of slots for each product
such that the aggregated influence of all the products gets maximized subject
to the following two constraints: total selection cost for each product is less
than or equal to the allocated budget for that product, and the difference
between the influence for any two products is less than or equal to a given
threshold. We show that the problem is NP-hard to solve optimally. We formulate
this problem as a linear programming problem and use linear programming
relaxation with randomized rounding. Further, we propose a greedy-based
heuristic with balance correction to solve this problem. We conduct a number of
experiments with real-world trajectory and billboard datasets, and the results
are reported. From the reported results, we observe that the proposed solution
approaches lead to more influence compared to many baseline methods.

- **SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models
  for Time Series**
  - 发表日期：2025-10-23 | 推荐度：0.815 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20273v1
  - 摘要：Recent advances in deep learning have driven rapid progress in time series
forecasting, yet many state-of-the-art models continue to struggle with robust
performance in real-world applications, even when they achieve strong results
on standard benchmark datasets. This persistent gap can be attributed to the
black-box nature of deep learning architectures and the inherent limitations of
current evaluation frameworks, which frequently lack the capacity to provide
clear, quantitative insights into the specific strengths and weaknesses of
different models, thereby complicating the selection of appropriate models for
particular forecasting scenarios. To address these issues, we propose a
synthetic data-driven evaluation paradigm, SynTSBench, that systematically
assesses fundamental modeling capabilities of time series forecasting models
through programmable feature configuration. Our framework isolates confounding
factors and establishes an interpretable evaluation system with three core
analytical dimensions: (1) temporal feature decomposition and capability
mapping, which enables systematic evaluation of model capacities to learn
specific pattern types; (2) robustness analysis under data irregularities,
which quantifies noise tolerance thresholds and anomaly recovery capabilities;
and (3) theoretical optimum benchmarking, which establishes performance
boundaries for each pattern type-enabling direct comparison between model
predictions and mathematical optima. Our experiments show that current deep
learning models do not universally approach optimal baselines across all types
of temporal features.The code is available at
https://github.com/TanQitai/SynTSBench

- **A comparison of methods for designing hybrid type 2 cluster-randomized
  trials with continuous effectiveness and implementation endpoints**
  - 发表日期：2025-10-23 | 推荐度：0.814 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20741v1
  - 摘要：Hybrid type 2 studies are gaining popularity for their ability to assess both
implementation and health outcomes as co-primary endpoints. Often conducted as
cluster-randomized trials (CRTs), five design methods can validly power these
studies: p-value adjustment methods, combined outcomes approach, single
weighted 1-DF test, disjunctive 2-DF test, and conjunctive test. We compared
all of the methods theoretically and numerically. Theoretical comparisons of
the power equations allowed us to identify if any method globally had more or
less power than other methods. It was shown that the p-value adjustment methods
are always less powerful than the combined outcomes approach and the single
1-DF test. We also identified the conditions under which the disjunctive 2-DF
test is less powerful than the single 1-DF test. Because our theoretical
comparison showed that some methods could be more powerful than others under
certain conditions, and less powerful under others, we conducted a numerical
study to understand these differences. The crt2power R package was created to
calculate the power or sample size for CRTs with two continuous co-primary
endpoints. Using this package, we conducted a numerical evaluation across
30,000 input scenarios to compare statistical power. Specific patterns were
identified where a certain method consistently achieved the highest power. When
the treatment effects are unequal, the disjunctive 2-DF test tends to have
higher power. When the treatment effect sizes are the same, the single 1-DF
test tends to have higher power. Together, these comparisons provide clearer
insights to guide method selection for powering hybrid type 2 studies.

- **Learning to Triage Taint Flows Reported by Dynamic Program Analysis in
  Node.js Packages**
  - 发表日期：2025-10-23 | 推荐度：0.813 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20739v1
  - 摘要：Program analysis tools often produce large volumes of candidate vulnerability
reports that require costly manual review, creating a practical challenge: how
can security analysts prioritize the reports most likely to be true
vulnerabilities?
  This paper investigates whether machine learning can be applied to
prioritizing vulnerabilities reported by program analysis tools. We focus on
Node.js packages and collect a benchmark of 1,883 Node.js packages, each
containing one reported ACE or ACI vulnerability. We evaluate a variety of
machine learning approaches, including classical models, graph neural networks
(GNNs), large language models (LLMs), and hybrid models that combine GNN and
LLMs, trained on data based on a dynamic program analysis tool's output. The
top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models
reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading
model eliminates 66.9% of benign packages from manual review, taking around 60
ms per package. If the best model is tuned to operate at a precision level of
0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can
detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating
strong potential for real-world vulnerability triage.

- **UI-Ins: Enhancing GUI Grounding with Multi-Perspective
  Instruction-as-Reasoning**
  - 发表日期：2025-10-23 | 推荐度：0.813 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20286v1
  - 摘要：GUI grounding, which maps natural-language instructions to actionable UI
elements, is a core capability of GUI agents. Prior works largely treats
instructions as a static proxy for user intent, overlooking the impact of
instruction diversity and quality on grounding performance. Through a careful
investigation of existing grounding datasets, we find a 23.3% flaw rate in
their instructions and show that inference-time exploitation of instruction
diversity yields up to a substantial 76% relative performance improvement. In
this paper, we introduce the Instruction-as-Reasoning paradigm, treating
instructions as dynamic analytical pathways that offer distinct perspectives
and enabling the model to select the most effective pathway during reasoning.
To achieve this, we propose a two-stage training framework: supervised
fine-tuning (SFT) on synthesized, diverse instructions to instill
multi-perspective reasoning, followed by reinforcement learning (RL) to
optimize pathway selection and composition. Our resulting models, UI-Ins-7B and
UI-Ins-32B, achieve state-of-the-art results on five challenging grounding
benchmarks and exhibit emergent reasoning, selectively composing and
synthesizing novel instruction pathways at inference. In particular, UI-Ins-32B
attains the best grounding accuracy, scoring 87.3% on UI-I2E-Bench, 57.0% on
ScreenSpot-Pro, and 84.9% on MMBench-GUI L2. Furthermore, our model
demonstrates strong agentic potential, achieving a 74.1% success rate on
AndroidWorld using UI-Ins-7B as the executor. Our in-depth analysis reveals
additional insights such as how reasoning can be formulated to enhance rather
than hinder grounding performance, and how our method mitigates policy collapse
in the SFT+RL framework. All code and model checkpoints will be publicly
released in https://github.com/alibaba/UI-Ins.

- **Addressing wavelength-correlated systematics in exoplanet transmission
  spectroscopy: a 2D Gaussian Process approach**
  - 发表日期：2025-10-23 | 推荐度：0.811 | 来源：arXiv
  - DOI：10.1117/12.3063572
  - 链接：http://arxiv.org/abs/2510.20423v1
  - 摘要：Ground-based transmission spectroscopy is often dominated by systematics,
which obstructs our ability to leverage the advantages of larger aperture sizes
compared to space-based observations. These systematics could be
time-correlated, uniform across all spectroscopic light curves, or
wavelength-correlated, which could significantly affect the characterization of
exoplanet atmospheres. Gaussian Processes were introduced in transmission
spectroscopy by Gibson et al. (2012) to model correlated systematics in a
non-parametric way. The technique uses auxiliary information about the
observation and independently fits each spectroscopic light curve to provide
robust atmospheric retrievals. However, this method assumes that the
uncertainties in the transmission spectrum are uncorrelated in wavelength,
which can cause discrepancies and degrade the precision of atmospheric
retrievals. To address this limitation, we explore a 2D GP framework formulated
by Fortune et al. (2024) to simultaneously model time- and
wavelength-correlated systematics. We present its application to ground-based
observations of TOI-4153b obtained using the 2-m Himalayan Chandra Telescope
(HCT). As we move towards detecting smaller and cooler planets, developing new
methods to address complex systematics becomes increasingly essential.

- **KL-Regularized Reinforcement Learning is Designed to Mode Collapse**
  - 发表日期：2025-10-23 | 推荐度：0.811 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20817v1
  - 摘要：It is commonly believed that optimizing the reverse KL divergence results in
"mode seeking", while optimizing forward KL results in "mass covering", with
the latter being preferred if the goal is to sample from multiple diverse
modes. We show -- mathematically and empirically -- that this intuition does
not necessarily transfer well to doing reinforcement learning with
reverse/forward KL regularization (e.g. as commonly used with language models).
Instead, the choice of reverse/forward KL determines the family of optimal
target distributions, parameterized by the regularization coefficient. Mode
coverage depends primarily on other factors, such as regularization strength,
and relative scales between rewards and reference probabilities. Further, we
show commonly used settings such as low regularization strength and equal
verifiable rewards tend to specify unimodal target distributions, meaning the
optimization objective is, by construction, non-diverse. We leverage these
insights to construct a simple, scalable, and theoretically justified
algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a
target distribution which puts high probability over all high-quality sampling
modes. In experiments, this simple modification works to post-train both Large
Language Models and Chemical Language Models to have higher solution quality
and diversity, without any external signals of diversity, and works with both
forward and reverse KL when using either naively fails.

- **All-Gaussian State Discrimination Beyond the Coherent Helstrom Bound**
  - 发表日期：2025-10-23 | 推荐度：0.810 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20096v1
  - 摘要：A core problem in communications is the optimal discrimination of
binary-phase-shift-keyed (BPSK) signals. A longstanding goal has been to reach
the fundamental quantum limit, known as the Helstrom bound, for BPSK signals
encoded in coherent states. However, due to technical constraints, proposals
for reaching the bound remain impractical. In this letter we take an
alternative approach: using only Gaussian optics - displaced squeezed states
and homodyne detection - we achieve discrimination of BPSK signals with error
rates below what can be achieved using coherent states and any quantum
measurement.

- **Partial Optimality in Cubic Correlation Clustering for General Graphs**
  - 发表日期：2025-10-23 | 推荐度：0.810 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20431v1
  - 摘要：The higher-order correlation clustering problem for a graph $G$ and costs
associated with cliques of $G$ consists in finding a clustering of $G$ so as to
minimize the sum of the costs of those cliques whose nodes all belong to the
same cluster. To tackle this NP-hard problem in practice, local search
heuristics have been proposed and studied in the context of applications. Here,
we establish partial optimality conditions for cubic correlation clustering,
i.e., for the special case of at most 3-cliques. We define and implement
algorithms for deciding these conditions and examine their effectiveness
numerically, on two data sets.

- **The Order of Recommendation Matters: Structured Exploration for
  Improving the Fairness of Content Creators**
  - 发表日期：2025-10-23 | 推荐度：0.810 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20698v1
  - 摘要：Social media platforms provide millions of professional content creators with
sustainable incomes. Their income is largely influenced by their number of
views and followers, which in turn depends on the platform's recommender system
(RS). So, as with regular jobs, it is important to ensure that RSs distribute
revenue in a fair way. For example, prior work analyzed whether the creators of
the highest-quality content would receive the most followers and income.
Results showed this is unlikely to be the case, but did not suggest targeted
solutions. In this work, we first use theoretical analysis and simulations on
synthetic datasets to understand the system better and find interventions that
improve fairness for creators. We find that the use of ordered pairwise
comparison overcomes the cold start problem for a new set of items and greatly
increases the chance of achieving fair outcomes for all content creators.
Importantly, it also maintains user satisfaction. We also test the intervention
on the MovieLens dataset and investigate its effectiveness on platforms with
interaction histories that are currently unfair for content creators. These
experiments reveal that the intervention improves fairness when deployed at
early stages of the platform, but the effect decreases as the strength of
pre-existing bias increases. Altogether, we find that the ordered pairwise
comparison approach might offer a plausible alternative for both new and
existing platforms to implement.

- **Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related
  Toxicities from Clinical Notes Using Natural Language Processing**
  - 发表日期：2025-10-23 | 推荐度：0.810 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20727v1
  - 摘要：Objective: Fluoropyrimidines are widely prescribed for colorectal and breast
cancers, but are associated with toxicities such as hand-foot syndrome and
cardiotoxicity. Since toxicity documentation is often embedded in clinical
notes, we aimed to develop and evaluate natural language processing (NLP)
methods to extract treatment and toxicity information.
  Materials and Methods: We constructed a gold-standard dataset of 236 clinical
notes from 204,165 adult oncology patients. Domain experts annotated categories
related to treatment regimens and toxicities. We developed rule-based, machine
learning-based (Random Forest, Support Vector Machine [SVM], Logistic
Regression [LR]), deep learning-based (BERT, ClinicalBERT), and large language
models (LLM)-based NLP approaches (zero-shot and error-analysis prompting).
Models used an 80:20 train-test split.
  Results: Sufficient data existed to train and evaluate 5 annotated
categories. Error-analysis prompting achieved optimal precision, recall, and F1
scores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot
prompting reached F1=1.000 for treatment and F1=0.876 for toxicities
extraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning
underperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and
ClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods
served as our baseline with F1 scores of 0.857 in treatment and 0.858 in
toxicities.
  Discussion: LMM-based approaches outperformed all others, followed by machine
learning methods. Machine and deep learning approaches were limited by small
training data and showed limited generalizability, particularly for rare
categories.
  Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine
treatment and toxicity information from clinical notes, and has strong
potential to support oncology research and pharmacovigilance.

- **A Soundness and Precision Benchmark for Java Debloating Tools**
  - 发表日期：2025-10-23 | 推荐度：0.808 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20679v1
  - 摘要：Modern software development reuses code by importing libraries as
dependencies. Software projects typically include an average of 36
dependencies, with 80% being transitive, meaning they are dependencies of
dependencies. Recent research indicates that only 24.9% of these dependencies
are required at runtime, and even within those, many program constructs remain
unused, adding unnecessary code to the project. This has led to the development
of debloating tools that remove unnecessary dependencies and program constructs
while balancing precision by eliminating unused constructs and soundness by
preserving all required constructs. To systematically evaluate this trade-off,
we developed Deblometer, a micro-benchmark consisting of 59 test cases designed
to assess support for various Java language features in debloating tools. Each
test case includes a manually curated ground truth specifying necessary and
bloated classes, methods, and fields, enabling precise measurement of soundness
and precision. Using Deblometer, we evaluated three popular Java debloating
tools: Deptrim, JShrink, and ProGuard. Our evaluation reveals that all tools
remove required program constructs, which results in changed semantics or
execution crashes. In particular, the dynamic class loading feature introduces
unsoundness in all evaluated tools. Our comparison shows that Deptrim retains
more bloated constructs, while ProGuard removes more required constructs.
JShrink's soundness is significantly affected by limited support for
annotations, which leads to corrupted debloated artifacts. These soundness
issues highlight the need to improve debloating tools to ensure stable and
reliable debloated software.

- **Compact representations of pattern-avoiding permutations**
  - 发表日期：2025-10-23 | 推荐度：0.807 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20382v1
  - 摘要：Pattern-avoiding permutations are a central object of study in both
combinatorics and theoretical computer science. In this paper we design a data
structure that can store any size-$n$ permutation $\tau$ that avoids an
arbitrary (and unknown) fixed pattern $\pi$ in the asymptotically optimal $O(n
\lg{s_\pi})$ bits, where $s_\pi$ is the Stanley-Wilf limit of $\pi$. Our data
structure supports $\tau(i)$ and $\tau^{-1}(i)$ queries in $O(1)$ time,
sidestepping the lower bound of Golynski (SODA 2009) that holds for general
permutations. Comparable results were previously known only in more restricted
cases, e.g., when $\tau$ is separable, which means avoiding the patterns 2413
and 3142.
  We also extend our data structure to support more complex geometric queries
on pattern-avoiding permutations (or planar point sets) such as rectangle range
counting in $O(\lg\lg{n})$ time. This result circumvents the lower bound of
$\Omega{(\lg{n}/\lg\lg{n})}$ by P\u{a}tra\c{s}cu (STOC 2007) that holds in the
general case. For bounded treewidth permutation classes (which include the
above-mentioned separable class), we further reduce the space overhead to a
lower order additive term, making our data structure succinct. This extends and
improves results of Chakraborty et al. (ISAAC 2024) that were obtained for
separable permutations via different techniques. All our data structures can be
constructed in linear time.

- **TRUST: A Decentralized Framework for Auditing Large Language Model
  Reasoning**
  - 发表日期：2025-10-23 | 推荐度：0.807 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20188v1
  - 摘要：Large Language Models generate complex reasoning chains that reveal their
decision-making, yet verifying the faithfulness and harmlessness of these
intermediate steps remains a critical unsolved problem. Existing auditing
methods are centralized, opaque, and hard to scale, creating significant risks
for deploying proprietary models in high-stakes domains. We identify four core
challenges: (1) Robustness: Centralized auditors are single points of failure,
prone to bias or attacks. (2) Scalability: Reasoning traces are too long for
manual verification. (3) Opacity: Closed auditing undermines public trust. (4)
Privacy: Exposing full reasoning risks model theft or distillation. We propose
TRUST, a transparent, decentralized auditing framework that overcomes these
limitations via: (1) A consensus mechanism among diverse auditors, guaranteeing
correctness under up to $30\%$ malicious participants. (2) A hierarchical DAG
decomposition of reasoning traces, enabling scalable, parallel auditing. (3) A
blockchain ledger that records all verification decisions for public
accountability. (4) Privacy-preserving segmentation, sharing only partial
reasoning steps to protect proprietary logic. We provide theoretical guarantees
for the security and economic incentives of the TRUST framework. Experiments
across multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,
medical, science, humanities) show TRUST effectively detects reasoning flaws
and remains robust against adversarial auditors. Our work pioneers
decentralized AI auditing, offering a practical path toward safe and
trustworthy LLM deployment.

- **\textsc{CantoNLU}: A benchmark for Cantonese natural language
  understanding**
  - 发表日期：2025-10-23 | 推荐度：0.807 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20670v1
  - 摘要：Cantonese, although spoken by millions, remains under-resourced due to policy
and diglossia. To address this scarcity of evaluation frameworks for Cantonese,
we introduce \textsc{\textbf{CantoNLU}}, a benchmark for Cantonese natural
language understanding (NLU). This novel benchmark spans seven tasks covering
syntax and semantics, including word sense disambiguation, linguistic
acceptability judgment, language detection, natural language inference,
sentiment analysis, part-of-speech tagging, and dependency parsing. In addition
to the benchmark, we provide model baseline performance across a set of models:
a Mandarin model without Cantonese training, two Cantonese-adapted models
obtained by continual pre-training a Mandarin model on Cantonese text, and a
monolingual Cantonese model trained from scratch. Results show that
Cantonese-adapted models perform best overall, while monolingual models perform
better on syntactic tasks. Mandarin models remain competitive in certain
settings, indicating that direct transfer may be sufficient when Cantonese
domain data is scarce. We release all datasets, code, and model weights to
facilitate future research in Cantonese NLP.

- **Fabrication and Structural Analysis of Trilayers for Tantalum Josephson
  Junctions with Ta$_2$O$_5$ Barriers**
  - 发表日期：2025-10-23 | 推荐度：0.805 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20114v1
  - 摘要：Tantalum (Ta) has recently emerged as a promising low-loss material, enabling
record coherence times in superconducting qubits. This enhanced performance is
largely attributed to its stable native oxide, which is believed to host fewer
two-level system (TLS) defects key $-$ contributors to decoherence in
superconducting circuits. Nevertheless, aluminum oxide (AlO$_x$) remains the
predominant choice for Josephson junction barriers in most qubit architectures.
In this study, we systematically investigate various techniques for forming
high-quality oxide layers on $\alpha$-phase tantalum ($\alpha$-Ta) thin films,
aiming to develop effective Josephson junction barriers. We explore thermal
oxidation in a tube furnace, rapid thermal annealing, as well as plasma
oxidation of both room-temperature and heated Ta films, and propose a
mechanistic picture of the underlying oxidation mechanisms. All methods yield
Ta$_2$O$_5$, the same compound as tantalum's native oxide. Among these, plasma
oxidation produces the smoothest and highest-quality oxide layers, making it
particularly well-suited for Josephson junction fabrication. Furthermore, we
demonstrate the successful epitaxial growth of $\alpha$-Ta atop oxidized
$\alpha$-Ta films, paving the way for the realization of trilayer Ta/Ta-O/Ta
Josephson junctions with clean, low-loss interfaces.

- **Probability model of edge-fault tolerance for regular graphs with
  respect to edge connectivity**
  - 发表日期：2025-10-23 | 推荐度：0.804 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20294v1
  - 摘要：We consider the probability model of edge-fault tolerance of a network in the
sense of connectivity with link faults. Using graph-theoretical notation, we
define the edge-fault (EF) and Menger-type edge-fault (MEF) tolerances of a
graph as the probabilities that the graph is connected and strongly Menger
edge-connected when each edge has a certain failure probability, respectively.
We derive an upper bound on the EF tolerance for regular graphs, which reveals
an asymptotical behavior when graphs and edge failure probability are large
enough. We also perform a simulation experiment on a number of randomly
generated regular graphs and some typically well-used graphs. The numerical
results show that, in addition to their well-structured properties for
networks, Hypercubes, M\"{o}bius Cubes, Ary-Cubes and Circulant graphs have
also higher EF and MEF tolerance in general. In particular, the M\"{o}bius Cube
has both the highest EF and MEF tolerance among all involved graphs. The
numerical results also hint that, in contrast to MEF tolerance, the EF
tolerance of regular graphs is not strongly effected by the graph structure.

- **Excluding a Line Minor via Design Matrices and Column Number Bounds for
  the Circuit Imbalance Measure**
  - 发表日期：2025-10-23 | 推荐度：0.804 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20301v1
  - 摘要：For a real matrix $A \in \mathbb{R}^{d \times n}$ with non-collinear columns,
we show that $n \leq O(d^4 \kappa_A)$ where $\kappa_A$ is the \emph{circuit
imbalance measure} of $A$. The circuit imbalance measure $\kappa$ is a real
analogue of $\Delta$-modularity for integer matrices, satisfying $\kappa_A \leq
\Delta_A$ for integer $A$. The circuit imbalance measure has numerous
applications in the context of linear programming (see Ekbatani, Natura and
V{\'e}gh (2022) for a survey). Our result generalizes the $O(d^4 \Delta_A)$
bound of Averkov and Schymura (2023) for integer matrices and provides the
first polynomial bound holding for all parameter ranges on real matrices.
  To derive our result, similar to the strategy of Geelen, Nelson and Walsh
(2021) for $\Delta$-modular matrices, we show that real representable matroids
induced by $\kappa$-bounded matrices are minor closed and exclude a rank $2$
uniform matroid on $O(\kappa)$ elements as a minor (also known as a line of
length $O(\kappa)$).
  As our main technical contribution, we show that any simple rank $d$ complex
representable matroid which excludes a line of length $l$ has at most $O(d^4
l)$ elements. This complements the tight bound of $(l-3)\binom{d}{2} + d$ for
$l \geq 4$, of Geelen, Nelson and Walsh which holds when the rank $d$ is
sufficiently large compared to $l$ (at least doubly exponential in $l$).

- **Well-Posedness and Approximation of Weak Solutions to Time Dependent
  Maxwell's Equations with $L^2$-Data**
  - 发表日期：2025-10-23 | 推荐度：0.803 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20752v1
  - 摘要：We study Maxwell's equations in conducting media with perfectly conducting
boundary conditions on Lipschitz domains, allowing rough material coefficients
and $L^2$-data. Our first contribution is a direct proof of well-posedness of
the first-order weak formulation, including solution existence and uniqueness,
an energy identity, and continuous dependence on the data. The argument uses
interior-in-time mollification to show uniqueness while avoiding reflection
techniques. Existence is via the well-known Galerkin method (cf.~Duvaut and
Lions \cite[Eqns.~(4.31)--(4.32), p.~346; Thm.~4.1]{GDuvaut_JLLions_1976a}).
For completeness, and to make the paper self-contained, a complete proof has
been provided.
  Our second contribution is a structure-preserving semi-discrete finite
element method based on the N\'ed\'elec/Raviart--Thomas de Rham complex. The
scheme preserves a discrete Gauss law for all times and satisfies a
continuous-in-time energy identity with stability for nonnegative conductivity.
With a divergence-free initialization of the magnetic field (via potential
reconstruction or constrained $L^2$ projection), we prove convergence of the
semi-discrete solutions to the unique weak solution as the mesh is refined. The
analysis mostly relies on projector consistency, weak-* compactness in
time-bounded $L^2$ spaces, and identification of time derivatives in dual
spaces.

- **Path-Based Conditions for the Identifiability of Non-additive Nonlinear
  Networks with Full Measurements**
  - 发表日期：2025-10-23 | 推荐度：0.803 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20537v1
  - 摘要：We analyze the identifiability of nonlinear networks with node dynamics
characterized by functions that are non-additive. We consider the full
measurement case (all the nodes are measured) in the path-independent delay
scenario where all the excitation signals of a specific node have the same
delay in the output of a measured node. Based on the notion of a generic
nonlinear matrix associated with the network, we introduce the concept of
generic identifiability and characterize the space of functions that satisfies
this property. For directed acyclic graphs (DAGs) characterized by analytic
functions, we derive a sufficient condition for identifiability based on
vertex-disjoint paths from excited nodes to the in-neighbors of each node in
the network. Furthermore, when we consider the class of polynomial functions,
by using well-known results on algebraic varieties, we prove that the
vertex-disjoint path condition is also necessary. Finally, we show that this
identifiability condition is not necessary for the additive nonlinear model.
Some examples are added to illustrate the results.

- **Anomalous Hall effect in rhombohedral graphene**
  - 发表日期：2025-10-23 | 推荐度：0.802 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20804v1
  - 摘要：Motivated by recent experiments on rhombohedral stacked multilayer graphene
and the observation of the anomalous Hall effect in a spontaneous spin-valley
polarized quarter metal state, we calculate the anomalous Hall conductivity for
this system in the presence of two types of impurities: weak and dense as well
as sparse and strong. Our calculation of $\sigma_{xy}$ is based on the
Kubo-Streda diagrammatic approach. In a model with Gaussian disorder applicable
to weak dense impurities, this involves all non-crossing diagrams (intrinsic,
side-jump and Gaussian skew-scattering contributions) and additionally diagrams
with two intersecting impurities, X and $\Psi$, representing diffractive
skew-scattering processes. A "Mercedes star" diagram (non-Gaussian skew
scattering) is furthermore included to treat in the case of strong, sparse
impurities. We supplement our asymptotically exact analytical solutions for an
isotropic model without warping effects by semi-numerical calculations
accounting perturbatively for warping, which plays a crucial role in the
low-energy band structure.

- **A Classification of Long-Refinement Graphs for Colour Refinement**
  - 发表日期：2025-10-23 | 推荐度：0.802 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20802v1
  - 摘要：The Colour Refinement algorithm is a classical procedure to detect symmetries
in graphs, whose most prominent application is in graph-isomorphism tests. The
algorithm and its generalisation, the Weisfeiler-Leman algorithm, evaluate
local information to compute a colouring for the vertices in an iterative
fashion. Different final colours of two vertices certify that no isomorphism
can map one onto the other. The number of iterations that the algorithm takes
to terminate is its central complexity parameter. For a long time, it was open
whether graphs that take the maximum theoretically possible number of Colour
Refinement iterations actually exist. Starting from an exhaustive search on
graphs of low degrees, Kiefer and McKay proved the existence of infinite
families of such long-refinement graphs with degrees 2 and 3, thereby showing
that the trivial upper bound on the iteration number of Colour Refinement is
tight. In this work, we provide a complete characterisation of the
long-refinement graphs with low (or, equivalently, high) degrees. We show that,
with one exception, the aforementioned families are the only long-refinement
graphs with maximum degree at most 3, and we fully classify the long-refinement
graphs with maximum degree 4. To this end, via a reverse-engineering approach,
we show that all low-degree long-refinement graphs can be represented as
compact strings, and we derive multiple structural insights from this
surprising fact. Since long-refinement graphs are closed under taking edge
complements, this also yields a classification of long-refinement graphs with
high degrees. Kiefer and McKay initiated a search for long-refinement graphs
that are only distinguished in the last iteration of Colour Refinement before
termination. We conclude it in this submission by showing that such graphs
cannot exist.

- **3D analytical theory of the perturbed single-synchronous state.
  Application to the post-impact Didymos-Dimorphos system**
  - 发表日期：2025-10-23 | 推荐度：0.801 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20317v1
  - 摘要：We develop the 3D generalization of the planar analytical theory presented in
Gaitanas et. al., 2024, which deals with states slightly perturbed from the
exact `single-synchronous equilibrium state' (SSES) of the full two-body
problem. The SSES corresponds to two non-spherical gravitationally interacting
bodies, settled in nearly circular relative orbit, with rotation axes normal to
the orbital plane, rapid rotation of the primary and synchronous rotation of
the secondary. In the present paper we remove all simplifying assumptions of
our previous work Gaitanas et. al., 2024, and show how to compute analytical
solutions describing a 3-dimensional perturbation of the system from the SSES
in the framework of two distinct theories, called `linear' and `nonlinear'.
Linear theory stems from averaging the equations of motion over the primary's
rapid rotation angle. This maps the SSES to an equilibrium point of the
averaged system, around which analytical solutions can be computed by
linearization of the equations of motion. In nonlinear theory, instead, we
compute a high order normal form for the Hamiltonian of motion through a
sequence of canonical transformations in the form of series. Resonances between
the basic system's frequencies appear in the nonlinear theory as small
divisors. We show that, close to resonances, the nonlinear theory leads to a
partially integrable model, sufficient to analytically describe the evolution
of the relative orbit, but only of some of the Euler angles of the system. As a
basic application, we compute analytical solutions representing various
possible Didymos-Dimorphos post-impact orbital and rotational states. In this
case, all analytical formulas here proposed are of direct utility in fitting
algorithms exploiting available time series of post-impact observational
data.}}

- **Deciding not to Decide: Sound and Complete Effect Inference in the
  Presence of Higher-Rank Polymorphism**
  - 发表日期：2025-10-23 | 推荐度：0.801 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20532v1
  - 摘要：Type-and-effect systems help the programmer to organize data and
computational effects in a program. While for traditional type systems
expressive variants with sophisticated inference algorithms have been developed
and widely used in programming languages, type-and-effect systems did not yet
gain widespread adoption. One reason for this is that type-and-effect systems
are more complex and the existing inference algorithms make compromises between
expressiveness, intuitiveness, and decidability. In this work, we present an
effect inference algorithm for a type-and-effect system with subtyping,
expressive higher-rank polymorphism, and intuitive set-like semantics of
effects. In order to deal with scoping issues of higher-rank polymorphism, we
delay solving of effect constraints by transforming them into formulae of
propositional logic. We prove soundness and completeness of our algorithm with
respect to a declarative type-and-effect system. All the presented results have
been formalized in the Rocq proof assistant, and the algorithm has been
successfully implemented in a realistic programming language.

- **A Linear Representation for Functions on Finite Sets**
  - 发表日期：2025-10-23 | 推荐度：0.800 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20167v1
  - 摘要：We demonstrate that any function $f$ from a finite set $Y$ to itself can be
represented linearly. Specifically, we prove the existence of an injective map
$j$ from $Y$ into a modular ring $\mathbb{Z}/m\mathbb{Z}$ and a constant $a \in
\mathbb{Z}/m\mathbb{Z}$ such that the relation $j(f(y)) = a \cdot j(y)$ in
$\mathbb{Z}/m\mathbb{Z}$ holds for all $y \in Y$. This result is established by
analyzing the algebraic properties of the adjugate of the characteristic matrix
associated with the function's digraph. The proof is constructive, providing a
method for finding the embedding $j$, the modulus $m$, and the linear
multiplier $a$.

- **Consumption-Investment Problem in Rank-Based Models**
  - 发表日期：2025-10-23 | 推荐度：0.800 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20763v1
  - 摘要：We study a consumption-investment problem in a multi-asset market where the
returns follow a generic rank-based model. Our main result derives an HJB
equation with Neumann boundary conditions for the value function and proves a
corresponding verification theorem. The control problem is nonstandard due to
the discontinuous nature of the coefficients in rank-based models, requiring a
bespoke approach of independent mathematical interest. The special case of
first-order models, prescribing constant drift and diffusion coefficients for
the ranked returns, admits explicit solutions when the investor is either (a)
unconstrained, (b) abides by open market constraints or (c) is fully invested
in the market. The explicit optimal strategies in all cases are related to the
celebrated solution to Merton's problem, despite the intractability of
constraint (b) in that setting.

- **A Deterministic Polylogarithmic Competitive Algorithm for Matching with
  Delays**
  - 发表日期：2025-10-23 | 推荐度：0.799 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20588v1
  - 摘要：In the online Min-cost Perfect Matching with Delays (MPMD) problem, $m$
requests in a metric space are submitted at different times by an adversary.
The goal is to match all requests while (i) minimizing the sum of the distances
between matched pairs as well as (ii) how long each request remained unmatched
after it appeared.
  While there exist almost optimal algorithms when the metric space is finite
and known a priori, this is not the case when the metric space is infinite or
unknown. In this latter case, the best known algorithm, due to Azar and
Jacob-Fanani, has competitiveness $\mathcal{O}(m^{0.59})$ which is
exponentially worse than the best known lower bound of $\Omega(\log m / \log
\log m)$ by Ashlagi et al.
  We present a $\mathcal{O}(\log^5 m)$-competitive algorithm for the MPMD
problem. This algorithm is deterministic and does not need to know the metric
space or $m$ in advance. This is an exponential improvement over previous
results and only a polylogarithmic factor away from the lower bound.

- **FinCARE: Financial Causal Analysis with Reasoning and Evidence**
  - 发表日期：2025-10-23 | 推荐度：0.799 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20221v1
  - 摘要：Portfolio managers rely on correlation-based analysis and heuristic methods
that fail to capture true causal relationships driving performance. We present
a hybrid framework that integrates statistical causal discovery algorithms with
domain knowledge from two complementary sources: a financial knowledge graph
extracted from SEC 10-K filings and large language model reasoning. Our
approach systematically enhances three representative causal discovery
paradigms, constraint-based (PC), score-based (GES), and continuous
optimization (NOTEARS), by encoding knowledge graph constraints algorithmically
and leveraging LLM conceptual reasoning for hypothesis generation. Evaluated on
a synthetic financial dataset of 500 firms across 18 variables, our
KG+LLM-enhanced methods demonstrate consistent improvements across all three
algorithms: PC (F1: 0.622 vs. 0.459 baseline, +36%), GES (F1: 0.735 vs. 0.367,
+100%), and NOTEARS (F1: 0.759 vs. 0.163, +366%). The framework enables
reliable scenario analysis with mean absolute error of 0.003610 for
counterfactual predictions and perfect directional accuracy for intervention
effects. It also addresses critical limitations of existing methods by
grounding statistical discoveries in financial domain expertise while
maintaining empirical validation, providing portfolio managers with the causal
foundation necessary for proactive risk management and strategic
decision-making in dynamic market environments.

- **Probing Neutron Skin through Event-by-Event Pion Asymmetry in Heavy-ion
  collisions**
  - 发表日期：2025-10-23 | 推荐度：0.797 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20166v1
  - 摘要：In this work, we propose a novel approach for probing the neutron skin
thickness of gold (Au) by analyzing the event-by-event distribution of
$\pi^{-}$ and $\pi^{+}$ yield differences. This is achieved through SMASH
simulations of ultra-peripheral Au+Au collisions at $\sqrt{s_{\rm NN}}=3$ GeV.
Our results demonstrate that the mean value of $\Delta n_{\pi} = n_{\pi^{-}} -
n_{\pi^{+}}$, along with the Pearson correlation and mutual information between
$(\pi^{-}+\pi^{+})$ and $(\pi^{-}-\pi^{+})$, all scale linearly with the
neutron skin thickness. Moreover, the slope of the line connecting two distinct
$\Delta n_{\pi}$ values in the event-by-event distribution also exhibits a
linear dependence on the neutron skin thickness. The most sensitive $\Delta
n_{\pi}$ pairs are identified as $(-1, 1)$, $(-1, 2)$, $(0, 1)$, and $(0, 2)$.
These findings establish a new pathway for determining the neutron skin
thickness. Finally, by comparing SMASH and UrQMD simulations under identical
initial conditions, we observe that individual slope values depend on the
specific collision model. However, by extracting slopes from multiple $\Delta
n_{\pi}$ pairs in experimental event-by-event data and inferring the
corresponding neutron skin thickness, one can assess which model better aligns
with the true physical value.

- **Microfluidic Study of Evaporation-Driven Crystallization of Saline and
  Ammonia Brines under Hydrogen Flow**
  - 发表日期：2025-10-23 | 推荐度：0.797 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20321v1
  - 摘要：Underground storage of hydrogen and ammonia in geological formations is
essential for renewable energy integration, but salt precipitation during gas
injection may threaten storage performance. While extensively studied for CO2
systems, precipitation mechanisms in hydrogen-brine and ammonia-brine systems
remain poorly understood. This study presents a comprehensive microfluidic
investigation of salt crystallization during hydrogen injection into saline and
ammonia-containing brines using high-pressure microfluidics. We conducted 81
high-pressure experiments systematically varying brine composition (1-5 mol/kg
NaCl), chemical additives (surfactants, alcohols, ammonia), and hydrogen flow
rates (200-1300 mL/min). Quantitative image analysis reveals that
hydrogen-induced precipitation differs fundamentally from CO2 systems. Hydrogen
drives physical precipitation via evaporation and capillary trapping, producing
discrete, localized deposits. In contrast, CO2-ammonia systems generate
extensive reactive precipitation of ammonium bicarbonate with interconnected
crystal networks. Interfacial tension (IFT) controls both residual brine
distribution and final crystal coverage: high-IFT fluids form large,
interconnected brine pools promoting extensive crystallization, while low-IFT
fluids create isolated pools reducing crystal coverage by 50\%. Alcohol and
surfactant additives suppress precipitation by enhancing brine mobility,
whereas ammonia paradoxically increases crystal fractions despite lower IFT.
Higher flow rates accelerate crystallization across all compositions, enabling
operational mitigation strategies. and demonstrate that gas-specific, rather
than CO2-analog, risk assessments are essential for underground hydrogen
storage design. The effectiveness of chemical additives offers promising
pathways for near-wellbore protection in underground hydrogen storage
operations.

- **Decentralized Exchange that Mitigate a Bribery Attack**
  - 发表日期：2025-10-23 | 推荐度：0.796 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20645v1
  - 摘要：Despite the popularity of Hashed Time-Locked Contracts (HTLCs) because of
their use in wide areas of applications such as payment channels, atomic swaps,
etc, their use in exchange is still questionable. This is because of its
incentive incompatibility and susceptibility to bribery attacks.
  State-of-the-art solutions such as MAD-HTLC (Oakland'21) and He-HTLC
(NDSS'23) address this by leveraging miners' profit-driven behaviour to
mitigate such attacks. The former is the mitigation against passive miners;
however, the latter works against both active and passive miners. However, they
consider only two bribing scenarios where either of the parties involved in the
transfer collude with the miner.
  In this paper, we expose vulnerabilities in state-of-the-art solutions by
presenting a miner-collusion bribery attack with implementation and
game-theoretic analysis. Additionally, we propose a stronger attack on MAD-HTLC
than He-HTLC, allowing the attacker to earn profits equivalent to attacking
naive HTLC.
  Leveraging our insights, we propose \prot, a game-theoretically secure HTLC
protocol resistant to all bribery scenarios. \prot\ employs a two-phase
approach, preventing unauthorized token confiscation by third parties, such as
miners. In Phase 1, parties commit to the transfer; in Phase 2, the transfer is
executed without manipulation. We demonstrate \prot's efficiency in transaction
cost and latency via implementations on Bitcoin and Ethereum.

- **Emergent time and more from wavefunction collapse in general relativity**
  - 发表日期：2025-10-23 | 推荐度：0.796 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20207v1
  - 摘要：In this paper, we further develop a recently proposed theory of time based on
wavefunction collapse in general relativity. It is based on the postulations
that quantum states, which violate the momentum and Hamiltonian constraints,
represent instances of time, and stochastic fluctuations of the lapse and shift
generate the time evolution under which an initial state gradually collapses
toward a diffeomorphism-invariant state. Under the wavefunction collapse, the
scale factor monotonically increases, thus acting as a clock. The scalar,
vector, and tensor gravitons arise as physical excitations, and the arrow of
time for their evolution is set by the initial state. In the long-time limit,
the tensor gravitons exhibit emergent unitary dynamics. However, the extra
modes are strongly damped due to the non-unitary dynamics that suppress the
constraint-violating excitations. The vector mode is uniformly suppressed over
all length scales, but the decay rate of the scalar is proportional to its wave
vector. This makes the latter a viable candidate for dark matter; excitations
with large wavelengths survive over long periods, contributing to long-range
interactions, while the fast decay of short-wavelength modes renders them
undetectable without sufficient temporal resolution. These are demonstrated for
the cosmological constant-dominated universe through semi-classical and
adiabatic approximations, which are controlled in the limit of large space
dimension.

- **Universal breathing mode scaling in harmonically trapped Fermi gases**
  - 发表日期：2025-10-23 | 推荐度：0.795 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20719v1
  - 摘要：We derive universal, experiment ready analytic laws for the breathing
(monopole) mode of harmonically trapped Fermi gases. Within a fixed
hyperangular channel $s>0$, contact-weighted products of associated Laguerre
polynomials reduce to an elementary gamma ratio, yielding: (i) a level resolved
fractional breathing mode shift with scaling $\delta\omega/(2\omega)\propto
Q^{-1}$, where $Q\equiv 2q+s+1$, with $q$ the radial quantum number; (ii) a
first order quantum anomaly correction involving exactly two intermediate
states, producing a $Q^{-2}$ falloff of the leaked monopole strength with an
explicit prefactor; and (iii) a closed form finite temperature average
exhibiting a low-$T$ plateau and a $1/T$ high-$T$ tail. We also obtain a mixed
anomaly\nobreakdash-quartic correction for weak anharmonicity. All expressions
become parameter free after a single per-channel calibration of the Tan contact
$\lambda_s$ at $q=0$.

- **Angular dependence and powder average of resonant inelastic X-ray
  scattering**
  - 发表日期：2025-10-23 | 推荐度：0.795 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20731v1
  - 摘要：Resonant Inelastic X-ray scattering (RIXS) is a synchrotron-based
spectroscopy that has seen growing interest across a range of scientific
disciplines beyond fundamental physics. The interpretation of experimental RIXS
data requires theoretical calculations based on the Kramers-Heisenberg formula.
However, due to the dependence of RIXS on both the incident and scattered
photon properties, a tractable treatment of the angular dependence in this
formula has been lacking. In this work, within the electric dipole
approximation, we determine the number of fundamental spectra contributing to
the RIXS cross-section for all crystallographic point groups. We then derive a
general expression for the RIXS cross-section of isotropic samples such as
un-textured powders, homogeneous glasses or liquids, explicitly accounting for
the polarization and propagation directions of both the incident and scattered
photons. Simplified forms of the RIXS expressions are subsequently obtained for
most common point groups. Finally, we demonstrate the applicability of our
formalism through a case study of uranium 3d4f RIXS.

- **Assessing the star formation history of all-sky and part-sky 100pc white
  dwarf samples**
  - 发表日期：2025-10-23 | 推荐度：0.795 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20624v1
  - 摘要：Thanks to Gaia and large-scale spectroscopic follow-up surveys (4MOST, DESI,
WEAVE, SDSS-V), it is now possible to build representative and minimally biased
samples of the local white dwarf population. Here we analyse several
volume-limited 100pc samples of white dwarfs, constructed from different
surveys and studies, to evaluate their completeness and residual biases. We
model the underlying star formation history and Galactic disc age via
comparison with simulated populations of white dwarfs to quantitatively
characterise completeness. We assess whether the benefit of Gaia XP spectra in
datasets outweighs the reduction in sample size, and to what extent targeted,
part-sky, and magnitude limited surveys can be used in comparison to all-sky
volume limited surveys. Additionally, we simulate the 4MOST 100PC sub-survey
and discuss its use to better understand the local star formation history.

- **Doubling the Number of Blue Large-Amlitude Pulsators: Final Results of
  Searches for BLAPs in the OGLE Inner Galactic Bulge Fields**
  - 发表日期：2025-10-23 | 推荐度：0.795 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20823v1
  - 摘要：Blue Large-Amplitude Pulsators (BLAPs) are rare short-period ($\lesssim$80
min) pulsating variable stars exhibiting large-amplitude brightness variations
(typically between 0.1 and 0.4 mag). As a recently discovered class of
radial-mode pulsators, the origin and nature of these variables remain the
subject of ongoing investigations. Here, we present a comprehensive summary of
all BLAPs identified in the data of the Optical Gravitational Lensing
Experiment (OGLE), including the discovery of 88 new BLAPs in the inner
Galactic bulge fields. We performed a systematic search for periodic signals in
the $I$-band light curves of more than 400 milion stars with magnitudes down to
$I = 21$. Our search effectively doubles the number of these variables to
almost 200. The detected BLAPs exhibit pulsation periods between roughly 5 and
76 minutes. The analyzed dataset covers a timespan from 2001 to 2024, with some
stars observed up to 20,000 times, providing the temporal coverage needed to
study period and amplitude variations. We report on three objects that show
enormous period changes, at a rate of $10^{-5}$ yr$^{-1}$, which could provide
important clues to the evolutionary status of BLAPs. Full dataset is
incorporated into the publicly available OGLE Collection of Variable Stars
(OCVS), enabling future studies of these enigmatic objects.

- **Real eigenvalue/vector distributions of random real antisymmetric
  tensors**
  - 发表日期：2025-10-23 | 推荐度：0.795 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20398v1
  - 摘要：Real eigenpairs of a real antisymmetric tensor of order $p$ and dimension $N$
can be defined as pairs of a real eigenvalue and $p$ orthonormal
$N$-dimensional real eigenvectors. We compute the signed and the genuine
distributions of such eigenvalues of Gaussian random real antisymmetric tensors
by using a quantum field theoretical method. An analytic expression for finite
$N$ is obtained for the signed distribution and the analytic large-$N$
asymptotic forms for both. We compute the edge of the distribution for
large-$N$, one application of which is to give an upper bound (believed tight)
of the injective norm of the random real antisymmetric tensor. We find a
large-$N$ universality across various tensor eigenvalue distributions: the
large-$N$ asymptotic forms of the distributions of the eigenvalues $z$ of the
complex, complex symmetric, real symmetric, and real antisymmetric random
tensors are all expressed by $e^{N\,B\, h_p(z_c^2/z^2)+o(N)}$, where the
function $h_p(\cdot)$ depends only on the order $p$, while $B$ and $z_c$ differ
for each case, $NB$ being the total dimension of the eigenvectors and $z_c$
being determined by the phase transition point of the quantum field theory.

- **Heterochromatic two-arm probabilities for metric graph Gaussian free
  fields**
  - 发表日期：2025-10-23 | 推荐度：0.794 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20492v1
  - 摘要：For the Gaussian free field on the metric graph of $\mathbb{Z}^d$ ($d\ge 3$),
we consider the heterochromatic two-arm probability, i.e., the probability that
two points $v$ and $v'$ are contained in distinct clusters of opposite signs
with diameter at least $N$. For all $d\ge 3$ except the critical dimension
$d_c=6$, we prove that this probability is asymptotically proportional to
$N^{-[(\frac{d}{2}+1)\land 4]}$. Furthermore, we prove that conditioned on this
two-arm event, the volume growth of each involved cluster is comparable to that
of a typical (unconditioned) cluster; precisely, each cluster has a volume of
order $M^{(\frac{d}{2}+1)\land 4}$ within a box of size $M$.

- **$L^1$ means of exponential sums with multiplicative coefficients. II**
  - 发表日期：2025-10-23 | 推荐度：0.794 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20194v1
  - 摘要：Let $f$ be a real-valued $1$-bounded multiplicative function. Suppose that
the mean-value of $f^{2}$ exists, and $$\int_{0}^{1} \Big | \sum_{n \leq N}
f(n)e^{2\pi i n \alpha} \Big | d \alpha\leq N^{o(1)}$$ as $N \rightarrow
\infty$, then there exists a quadratic character $\chi$ such that for every
$\delta > 0$ the (logarithmic) proportion of primes $p \leq N$ such that $|f(p)
- \chi(p)| < \delta$ tends to $1$ as $N \rightarrow \infty$. More generally we
show that for all $N, \Delta \geq 1$ and $1$-bounded multiplicative functions
$f$, if $$\int_{0}^{1} \Big | \sum_{n \leq N} f(n) e^{2\pi i n \alpha} \Big | d
\alpha \leq \Delta$$ and the $L^{2}$ norm of $f$ over $[1, N]$ is $\geq N /
100$, then $f$ pretends to be a multiplicative character of conductor $\leq
\Delta^{2}$ on primes in $[\Delta^{2}, N]$. We highlight that the result is
uniform in $f$, $N$ and $\Delta$ and sharp as far as the size of the conductor
goes. Moreover, the restriction to primes $p \in [\Delta^{2}, N]$ turns out to
be sharp in a suitably generalized version of this result, concerning sequences
$f$ that are close $1\%$ of the time to multiplicative functions.

- **Critical Dynamics of Holographic Superfluids**
  - 发表日期：2025-10-23 | 推荐度：0.793 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20761v1
  - 摘要：We study the nearly critical behaviour of holographic superfluids at finite
temperature and chemical potential. Using analytic techniques in the bulk, we
derive an effective theory for the long wavelength dynamics of gapless and
pseudo-gapped modes, at first subleading order in a derivative expansion and we
match the classical limit of our field theory construction in a companion
paper. Specifically, we obtain the constitutive relations for the stress tensor
and electric current, as well as a time evolution equation for the order
parameter at next-to-leading order. In addition, we get explicit formulas for
all the transport coefficients in terms of background quantities. We carry out
numerical cross-checks with the predictions of our effective theory close to
the critical point.

- **Black Hole-Host Galaxy Correlations with Machine Learning: A Comparative
  Study of Illustris, TNG, and EAGLE**
  - 发表日期：2025-10-23 | 推荐度：0.793 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20751v1
  - 摘要：Supermassive black holes (SMBHs) are known to correlate with many properties
of their host galaxies, but we do not fully understand these correlations. The
strengths (tightness) of these correlations have also been widely debated. In
this work, we explore SMBH-host relations in three state-of-the-art
cosmological simulations: Illustris, TNG, and EAGLE. Using a variety of machine
learning regressors, we measure the scaling relations between black hole mass
($M_{\rm BH}$) and galaxy properties including stellar velocity dispersion
($\sigma$), stellar mass ($M_{\star}$), dark matter halo mass ($M_{\rm Halo}$),
and the Sersic index. We find that machine learning regressors provide
predictive capabilities superior to linear regression in many scaling relations
in simulations, and Multi-layer Perceptron (MLP) regressor has the strongest
performance. SMBH-host relations have different strengths in different
simulations as a result of their sub-grid models. Similar to the observations,
the $M_{\rm BH} $-$\sigma$ relation is a strong correlation in all simulations,
but in TNG, the $M_{\rm BH} $-$M_{\star}$ relation is even tighter than $M_{\rm
BH} $-$\sigma$. EAGLE produces the weakest SMBH-host correlations among all
simulations. Low mass SMBHs tend to be poorly correlated with their host
galaxies, but including them can still help machines better grasp the
correlations in Illustris and TNG. Combining galaxy properties that strongly
correlate with $M_{\rm BH} $ but poorly correlate with each other can improve
MLP's performance. $M_{\rm BH} $ is most accurately predicted when all galaxy
properties are included in the training, suggesting that SMBH-host correlations
are fundamentally multi-dimensional in these simulations.

- **Beneath the kinetic interpretation of noise**
  - 发表日期：2025-10-23 | 推荐度：0.793 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20552v1
  - 摘要：Diffusion theory establishes a fundamental connection between stochastic
differential equations and partial differential equations. The solution of a
partial differential equation known as the Fokker-Planck equation describes the
probability density of the stochastic process that solves a corresponding
stochastic differential equation. The kinetic interpretation of noise refers to
a prospective notion of stochastic integration that would connect a stochastic
differential equation with a Fokker-Planck equation consistent with the Fick
law of diffusion, without introducing correction terms in the drift. This work
is devoted to identifying the precise conditions under which such a
correspondence can occur. One of these conditions is a structural constraint on
the diffusion tensor, which severely restricts its possible form and thereby
renders the kinetic interpretation of noise a non-generic situation. This point
is illustrated through a series of examples. Furthermore, the analysis raises
additional questions, including the possibility of defining a stochastic
integral inspired by numerical algorithms, the behavior of stochastic transport
equations in heterogeneous media, and the development of alternative models for
anomalous diffusion. All these topics are addressed using stochastic analytical
tools similar to those employed to study the main problem: the existence of the
kinetic interpretation of noise.

- **Quantitative classification of potential Navier-Stokes singularities
  beyond the blow-up time**
  - 发表日期：2025-10-23 | 推荐度：0.791 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20757v1
  - 摘要：In \cite{hou}, Hou gave a compelling numerical candidate for a singular
solution of the 3D Navier-Stokes equations. We pioneer classifications of
potentially singular solutions, motivated by the issue of investigating the
viability of numerical candidates.For approximately axisymmetric initial data,
we give the first quantitative classification of potentially singular solutions
at \textit{any} given time in the region of potential blow-up times. Moreover,
the quantitative bounds in the vicinity of any potential blow-up time are in
principle amenable to numerical testing. To achieve this, we establish improved
quantitative regions of regularity for approximately axisymmetric initial data,
which may be of independent interest. Together with improved quantitative
energy estimates from \cite{TB24}, this allows us to get a quantitative lower
bound in the vicinity of a blow-up time by implementing the strategy of
\cite{BP21}, which is a physical space analogue of Tao's strategy \cite{Ta21}
for producing quantitative estimates for critically bounded solutions. To
obtain a quantitative lower bound on the solution at any time in the region of
potential blow-up times, we recursively apply quantitative Carleman inequality
arguments from \cite{Ta21}. This necessitates careful bookkeeping to avoid
exponential losses and to ensure that all forward-in-time iterations of
(localized) vorticity concentration remain within the region of quantitative
regularity of the solution.

- **On Casagrande-Druel Fano varieties with Lefschetz defect 2**
  - 发表日期：2025-10-23 | 推荐度：0.790 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20732v1
  - 摘要：The larger the Lefschetz defect delta(X) of a smooth complex Fano variety X,
the more information we can deduce about the geometry of X. The structure of
varieties with delta(X) greater than 2 is known. In this paper, we study the
case delta(X)=2. In particular, we focus on Fano varieties with delta(X)=2
arising from the so called Casagrande-Druel construction, which we refer to as
Construction A. We show that among the 19 families of Fano 3-folds with
delta(X)=2 classified by Mori and Mukai, 15 arise from such construction.
Moreover, we construct all Fano 4-folds with Picard number greater than 3 and
delta(X)=2 admitting such a structure, obtaining 147 distinct families in
total. This completes the classification of all Casagrande-Druel Fano 4-folds
with delta(X)=2. To broaden the scope, we also study a generalized version of
Construction A, which we call Construction B, and we show that 18 out of the 19
families of Fano 3-folds with delta(X)=2 arise from it.

- **Optimal quantitative stability estimates for Alexandrov's Soap Bubble
  Theorem via Gagliardo-Nirenberg-type interpolation inequalities**
  - 发表日期：2025-10-23 | 推荐度：0.789 | 来源：arXiv
  - DOI：
  - 链接：http://arxiv.org/abs/2510.20399v1
  - 摘要：The paper provides optimal quantitative stability estimates for the
celebrated Alexandrov's Soap Bubble Theorem within the class of $C^{k,\alpha}$
domains, for any $k \ge 1$ and $0 < \alpha \le 1$, by leveraging
Gagliardo-Nirenberg-type interpolation inequalities.
  Optimal estimates of uniform closeness to a ball are established for $L^r$
deviations of the mean curvature from being constant, for any $r\ge 2$ (more
generally, for any $r>1$ such that $r\ge (2N-2)/(N+1)$).
  For $r>\frac{N-1}{2}$, the stability profile is linear, thus returning the
existing results established in the literature through computations for nearly
spherical sets. Surprisingly, all the stability estimates for $r\ge
\frac{N-1}{2}$, for which the profile is not linear, are new; even in the
particular case $r=2$ (which has been extensively studied, since it is a case
of interest for several critical applications), the sharp stability profile
that we obtain is new. Interestingly, we also prove that the (non-linear)
profile for $r \ge \frac{N-1}{2}$ improves as $k$ becomes larger to such an
extent that it becomes formally linear as $k$ goes to $\infty$.
  Finally, for any $r$, we show that all our estimates are optimal for any $k
\ge 1$ and $0< \alpha \le 1$, by providing explicit examples.
